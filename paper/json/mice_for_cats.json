{
    "paper_id": "mice_for_cats",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2025-12-04T19:10:32.016045Z"
    },
    "title": "MICE for CATs: Model-Internal Confidence Estimation for Calibrating Agents with Tools",
    "authors": [
        {
            "first": "Nishant",
            "middle": [],
            "last": "Subramani",
            "suffix": "",
            "affiliation": {},
            "email": "nishant2@cs.cmu.edu"
        },
        {
            "first": "Jason",
            "middle": [],
            "last": "Eisner",
            "suffix": "",
            "affiliation": {},
            "email": "jason.eisner@microsoft.com"
        },
        {
            "first": "Justin",
            "middle": [],
            "last": "Svegliato",
            "suffix": "",
            "affiliation": {},
            "email": "jsvegliato@microsoft.com"
        },
        {
            "first": "Benjamin",
            "middle": [],
            "last": "Van Durme",
            "suffix": "",
            "affiliation": {},
            "email": "ben.vandurme@microsoft.com"
        },
        {
            "first": "Yu",
            "middle": [],
            "last": "Su",
            "suffix": "",
            "affiliation": {},
            "email": ""
        },
        {
            "first": "Sam",
            "middle": [],
            "last": "Thomson",
            "suffix": "",
            "affiliation": {},
            "email": "samuel.thomson@microsoft.com"
        }
    ],
    "year": "",
    "venue": null,
    "identifiers": {},
    "abstract": "Tool-using agents that act in the world need to be both useful and safe. Well-calibrated model confidences can be used to weigh the risk versus reward of potential actions, but prior work shows that many models are poorly calibrated. Inspired by interpretability literature exploring the internals of models, we propose a novel class of model-internal confidence estimators (MICE) to better assess confidence when calling tools. MICE first decodes from each intermediate layer of the language model using logit lens (nostalgebraist, 2020) and then computes similarity scores between each layer's generation and the final output. These features are fed into a learned probabilistic classifier to assess confidence in the decoded output. On the simulated trial and error (STE) tool-calling dataset using Llama3 models, we find that MICE beats or matches the baselines on smoothed expected calibration error. Using MICE confidences to determine whether to call a tool significantly improves over strong baselines on a new metric, expected tool-calling utility. Further experiments show that MICE is sample-efficient, can generalize zero-shot to unseen APIs, and results in higher tool-calling utility in scenarios with varying risk levels.\nOur code is open source, available at https: //github.com/microsoft/mice_for_cats.",
    "pdf_parse": {
        "paper_id": "mice_for_cats",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": "Tool-using agents that act in the world need to be both useful and safe. Well-calibrated model confidences can be used to weigh the risk versus reward of potential actions, but prior work shows that many models are poorly calibrated. Inspired by interpretability literature exploring the internals of models, we propose a novel class of model-internal confidence estimators (MICE) to better assess confidence when calling tools. MICE first decodes from each intermediate layer of the language model using logit lens (nostalgebraist, 2020) and then computes similarity scores between each layer's generation and the final output. These features are fed into a learned probabilistic classifier to assess confidence in the decoded output. On the simulated trial and error (STE) tool-calling dataset using Llama3 models, we find that MICE beats or matches the baselines on smoothed expected calibration error. Using MICE confidences to determine whether to call a tool significantly improves over strong baselines on a new metric, expected tool-calling utility. Further experiments show that MICE is sample-efficient, can generalize zero-shot to unseen APIs, and results in higher tool-calling utility in scenarios with varying risk levels.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            },
            {
                "text": "Our code is open source, available at https: //github.com/microsoft/mice_for_cats.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "Language models are increasingly being used as tool-using agents, where they can generate executable API calls that can change external environments (Schick et al., 2024; Yan et al., 2024; Wang et al., 2024; Roy et al., 2024) . Sometimes the generated tool calls are relatively safe, and mistakes will have minimal impact (e.g., if \"how many grand slams has Serena Williams won?\" resulted in the incorrect tool call tennis_reference_count_grand_slams( name=\"venus williams\"), then the user would just be misinformed). But other times, incorrect tool calls can be more harmful (e.g., if \"please remove slash.txt\" resulted in the incorrect tool call cli(args=\"rm -rf /\"), then the user would lose the contents of their filesystem).",
                "cite_spans": [
                    {
                        "start": 149,
                        "end": 170,
                        "text": "(Schick et al., 2024;",
                        "ref_id": "BIBREF35"
                    },
                    {
                        "start": 171,
                        "end": 188,
                        "text": "Yan et al., 2024;",
                        "ref_id": "BIBREF51"
                    },
                    {
                        "start": 189,
                        "end": 207,
                        "text": "Wang et al., 2024;",
                        "ref_id": "BIBREF46"
                    },
                    {
                        "start": 208,
                        "end": 225,
                        "text": "Roy et al., 2024)",
                        "ref_id": "BIBREF34"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "A confidence estimator estimates the probability that another model's output is correct. A simple confidence estimator for a language model would be based on the probability that the model itself assigns to its output (i.e., the product of token probabilities) or to its output's semantic equivalence class (Zhong et al., 2023; Farquhar et al., 2024 ). Yet prior work has shown that this method can be poorly calibrated (Jiang et al., 2021; Mielke et al., 2022; Kadavath et al., 2022; Yin et al., 2023) . A probabilistic classifier is well calibrated if on an unseen test distribution, it is correct about as often as it thinks it is (Dawid, 1982; Guo et al., 2017; Desai and Durrett, 2020; Zhao et al., 2021; Hashemi et al., 2024) . For example, of those unseen examples that it predicts to be positive with \u2248 25% probability, \u2248 25% really are positive. Well-calibrated probabilities can be used to guide downstream decisions, but calibration should never be one's only engineering target, as even a highly unsure classifier may be well-calibrated (see \u00a73.1).",
                "cite_spans": [
                    {
                        "start": 307,
                        "end": 327,
                        "text": "(Zhong et al., 2023;",
                        "ref_id": "BIBREF56"
                    },
                    {
                        "start": 328,
                        "end": 349,
                        "text": "Farquhar et al., 2024",
                        "ref_id": "BIBREF12"
                    },
                    {
                        "start": 420,
                        "end": 440,
                        "text": "(Jiang et al., 2021;",
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 441,
                        "end": 461,
                        "text": "Mielke et al., 2022;",
                        "ref_id": "BIBREF24"
                    },
                    {
                        "start": 462,
                        "end": 484,
                        "text": "Kadavath et al., 2022;",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 485,
                        "end": 502,
                        "text": "Yin et al., 2023)",
                        "ref_id": null
                    },
                    {
                        "start": 634,
                        "end": 647,
                        "text": "(Dawid, 1982;",
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 648,
                        "end": 665,
                        "text": "Guo et al., 2017;",
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 666,
                        "end": 690,
                        "text": "Desai and Durrett, 2020;",
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 691,
                        "end": 709,
                        "text": "Zhao et al., 2021;",
                        "ref_id": "BIBREF55"
                    },
                    {
                        "start": 710,
                        "end": 731,
                        "text": "Hashemi et al., 2024)",
                        "ref_id": "BIBREF16"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "To that end, we introduce a class of modelinternal confidence estimators (MICE) and an end-to-end metric, expected tool-calling utility (ETCU), to evaluate a tool-calling agent that consults a confidence estimator to decide when to launch the predicted tool call.1 MICE extracts fea- tures by decoding from the intermediate layers of a transformer-based large language model (LLM) and computes the similarities of those generations to the output of the final layer. Based on these features and the LLM's raw confidence, it learns a model that outputs a confidence score. MICE excels on ETCU, increasingly outperforming two strong baselines as the cost of incorrect tool calls increases, without increasing calibration error.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "This paper makes the following contributions: We propose a class of model-internal confidence estimators (MICE) that are empirically wellcalibrated on the task of assessing generated tool calls ( \u00a72). We introduce a new metric, expected tool-calling utility, that combines accuracy and calibration to better evaluate tool-calling agents ( \u00a73). Finally, we show that MICE is sample-efficient and can generalize to new tools, even in a zero-shot setting ( \u00a75).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "MICE is a simple learned probabilistic classifier whose features are derived from model-internal activations. Prior work on understanding the internals of transformer language models has shown that intermediate layers at different depths encode different types of information, and that the activation spaces at various layers of these models can be nudged to generate sequences in targeted ways (Tenney et al., 2019; Subramani et al., 2019; Subramani and Suresh, 2020; Subramani et al., 2022; Turner et al., 2023) . Decoding from the layers of a transformer language model has provided insight into the underlying mechanisms and has been used in early-exit algorithms for faster generation (nostalgebraist, 2020; Geva et al., 2022; Schuster et al., 2022; Belrose et al., 2023) . For question answering tasks, decoding from roughly the first half of the layers of the language model produces unintelligible results, but in later layers the model's predictions slowly refine into a plausible answer (Merullo et al., 2024) .",
                "cite_spans": [
                    {
                        "start": 395,
                        "end": 416,
                        "text": "(Tenney et al., 2019;",
                        "ref_id": "BIBREF44"
                    },
                    {
                        "start": 417,
                        "end": 440,
                        "text": "Subramani et al., 2019;",
                        "ref_id": "BIBREF40"
                    },
                    {
                        "start": 441,
                        "end": 468,
                        "text": "Subramani and Suresh, 2020;",
                        "ref_id": "BIBREF41"
                    },
                    {
                        "start": 469,
                        "end": 492,
                        "text": "Subramani et al., 2022;",
                        "ref_id": "BIBREF42"
                    },
                    {
                        "start": 493,
                        "end": 513,
                        "text": "Turner et al., 2023)",
                        "ref_id": "BIBREF45"
                    },
                    {
                        "start": 690,
                        "end": 712,
                        "text": "(nostalgebraist, 2020;",
                        "ref_id": null
                    },
                    {
                        "start": 713,
                        "end": 731,
                        "text": "Geva et al., 2022;",
                        "ref_id": "BIBREF13"
                    },
                    {
                        "start": 732,
                        "end": 754,
                        "text": "Schuster et al., 2022;",
                        "ref_id": "BIBREF36"
                    },
                    {
                        "start": 755,
                        "end": 776,
                        "text": "Belrose et al., 2023)",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 997,
                        "end": 1019,
                        "text": "(Merullo et al., 2024)",
                        "ref_id": "BIBREF23"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Model-Internal Confidence Estimators",
                "sec_num": "2"
            },
            {
                "text": "We hypothesize that features from intermediate layers' hidden states could provide useful signal for calibration. Drastic changes in the final few layers could indicate the inability for the LLM to pinpoint a tool call. As a result, we may trust a prediction that was slowly refined into an answer over the final 50% of layers more than one that drastically changed in the final few layers, even if they had the same distribution at the end.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Model-Internal Confidence Estimators",
                "sec_num": "2"
            },
            {
                "text": "BERTScore Features Since we hypothesize that intermediate layers' hidden states could be a useful signal for calibration beyond the confidences derived from the final layer, we decode from each layer, much as in logit lens (nostalgebraist, 2020), a model interpretation technique. We first decode the output string y at temperature 0. This is the usual way to obtain model output in a task like tool calling. Then at each layer i < \u2113, we obtain a preliminary output string y (i) of the same length by per-token argmax decoding:2 ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Model-Internal Confidence Estimators",
                "sec_num": "2"
            },
            {
                "text": "y (i) t = argmax h (i) t-1 W out (1)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Model-Internal Confidence Estimators",
                "sec_num": "2"
            },
            {
                "text": "where each t is a token position in y, and the row vector h",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Model-Internal Confidence Estimators",
                "sec_num": "2"
            },
            {
                "text": "(i)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Model-Internal Confidence Estimators",
                "sec_num": "2"
            },
            {
                "text": "t-1 \u2208 R d is the model's layer-i encoding at the previous position, whose product with the unembedding matrix W out \u2208 R d\u00d7|V | is a vector of logits \u2208 R |V | . Here, d is the embedding size and |V | is the vocabulary size. This results in \u2113 strings, where \u2113 is the number of layers of the model.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Model-Internal Confidence Estimators",
                "sec_num": "2"
            },
            {
                "text": "We then compute the BERTScore (Zhang et al., 2020) between y and each y (i) . These become the main input features to the MICE model. 3Raw Confidence Feature We also integrate the raw confidence of the language model in generating the tool call as a feature to the MICE model. We calculate this by computing the product of the probabilities of the tokens in the generated tool call. We Figure 3 : BERTScore similarities between the generated string y and the preliminary strings y (i) from earlier layers, for Llama3-8B-Instruct on the STE validation set (Wang et al., 2024) . See also Figure 8 in Appendix A.",
                "cite_spans": [
                    {
                        "start": 30,
                        "end": 50,
                        "text": "(Zhang et al., 2020)",
                        "ref_id": "BIBREF54"
                    },
                    {
                        "start": 555,
                        "end": 574,
                        "text": "(Wang et al., 2024)",
                        "ref_id": "BIBREF46"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 393,
                        "end": 394,
                        "text": "3",
                        "ref_id": null
                    },
                    {
                        "start": 593,
                        "end": 594,
                        "text": "8",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Model-Internal Confidence Estimators",
                "sec_num": "2"
            },
            {
                "text": "notice that including formatting tokens, which are always present in the tool call, leads to increased noise and a less accurate estimate of confidence, so we omit the tokens associated with formatting. The gray tokens in Figure 1 were omitted, while the green ones were included.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 229,
                        "end": 230,
                        "text": "1",
                        "ref_id": "FIGREF0"
                    }
                ],
                "eq_spans": [],
                "section": "Model-Internal Confidence Estimators",
                "sec_num": "2"
            },
            {
                "text": "Model Architecture We train a simple supervised classifier that predicts whether the generated tool call y is correct. It maps from the input features-the BERTScores and the raw confidence-to a probability of correctness (i.e., a confidence estimate). Any trainable model of this form could be used here; the specific architectures and baselines that we tried will be described in \u00a74.4.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Model-Internal Confidence Estimators",
                "sec_num": "2"
            },
            {
                "text": "Perhaps the most widely reported calibration metric is expected calibration error ( \u00a73.1). As mentioned in the introduction, however, minimizing ECE should not be our only goal. We also introduce a utility metric, expected tool-calling utility ( \u00a73.2), to assess the performance of a simple agent that makes call/no-call decisions by using our well-calibrated confidence estimates. This metric is parameterized by the cost of false positives relative to the reward of true positives.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Metrics",
                "sec_num": "3"
            },
            {
                "text": "Expected calibration error (ECE; Naeini et al., 2014 Naeini et al., , 2015) ) is computed by constructing a histogram binned by predicted confidence, p. The accuracy of examples within a given bin is compared to the mean predicted confidence within that bin, |acc -p|. These absolute differences are then averaged across bins, with each bin weighted by the fraction of examples in that bin.",
                "cite_spans": [
                    {
                        "start": 27,
                        "end": 32,
                        "text": "(ECE;",
                        "ref_id": null
                    },
                    {
                        "start": 33,
                        "end": 52,
                        "text": "Naeini et al., 2014",
                        "ref_id": "BIBREF26"
                    },
                    {
                        "start": 53,
                        "end": 77,
                        "text": "Naeini et al., , 2015) )",
                        "ref_id": "BIBREF27"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Expected Calibration Error (ECE)",
                "sec_num": "3.1"
            },
            {
                "text": "We use a recently improved variant of ECE, smooth ECE (smECE; B\u0142asiok and Nakkiran, 2024) , which replaces histogram binning with Nadaraya-Watson kernel regression (Nadaraya, 1964; Watson, 1964) . A reflected Gaussian kernel is used; the kernel width is determined automatically from the data, yielding a consistent estimator.",
                "cite_spans": [
                    {
                        "start": 62,
                        "end": 89,
                        "text": "B\u0142asiok and Nakkiran, 2024)",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 164,
                        "end": 180,
                        "text": "(Nadaraya, 1964;",
                        "ref_id": "BIBREF25"
                    },
                    {
                        "start": 181,
                        "end": 194,
                        "text": "Watson, 1964)",
                        "ref_id": "BIBREF50"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Expected Calibration Error (ECE)",
                "sec_num": "3.1"
            },
            {
                "text": "However, ECE and smECE do not distinguish between an oracle classifier that returns p = 1.0 on correct outputs and p = 0.0 on incorrect outputs, and a maximally uninformative probabilistic classifier that always predicts the base accuracy rate. That is, if 70% of all predictions are correct, then a trivial system that gave p = 0.7 on every example would be perfectly calibrated (ECE = 0), yet mostly useless! We would prefer a system that tends to return high p on correct tool calls and low p on incorrect ones, so that we can execute the former and avoid executing the latter.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Expected Calibration Error (ECE)",
                "sec_num": "3.1"
            },
            {
                "text": "We thus introduce a parameterized metric, expected tool-calling utility, which approximates actual utility in situations where a calibrated confidence score p is used to decide of whether or not to execute a specific tool call generated by the language model. We assume we know the expected utility for each of the four possible outcomes: tp > 0 (true positive), for when the agent executes a correctly predicted call; fp < 0 (false positive), for when the agent executes an incorrectly predicted call; tn \u2248 0 (true negative), for when the agent avoids executing an incorrect call; fn \u2248 0 (false negative), for when the agent fails to execute a correct call. tn and fn may be slightly negative to account for time wasted making the unused prediction. fp may be highly negative, e.g., if the agent erroneously deletes all of the user's documents, makes a large unintended purchase, or sends an offensive email.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Expected Tool-Calling Utility (ETCU)",
                "sec_num": "3.2"
            },
            {
                "text": "The exact values of tp, fp, tn, and fn will depend on the specific task that the agent must perform, and could be assigned by a domain expert or learned from data, like human preferences (Christiano et al., 2017) . 4 Once these values have been assigned, the minimum Bayes risk (MBR; Bickel and Doksum, 1977, p. 27 ) decision can be calculated; it is to execute the predicted tool call if and only if the estimated confidence p is above the threshold 4 They will also often depend on the predicted API and arguments. A more careful MBR practitioner would ideally condition on these and assign utilities to each possible pair (gold specific action, chosen specific action). Our coarser expectations {tp, fp, tn, fn} result in cruder decisions.",
                "cite_spans": [
                    {
                        "start": 187,
                        "end": 212,
                        "text": "(Christiano et al., 2017)",
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 284,
                        "end": 314,
                        "text": "Bickel and Doksum, 1977, p. 27",
                        "ref_id": null
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Expected Tool-Calling Utility (ETCU)",
                "sec_num": "3.2"
            },
            {
                "text": "p > \u03c4 def = tn -fp (tp -fn) + (tn -fp) (2)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Expected Tool-Calling Utility (ETCU)",
                "sec_num": "3.2"
            },
            {
                "text": "Calibration ensures that of all predicted tool calls with confidence \u2248 p, about p are correct. The decision rule (2) makes either all such calls or none of them, according to whether the expected utility per call is higher with all (p tp+(1-p) fp) or with none (p fn + (1 -p) tn). The threshold \u03c4 is high (> 0.5) if avoiding bad calls (benefit tnfp) is more important than executing good calls (benefit tpfn).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Expected Tool-Calling Utility (ETCU)",
                "sec_num": "3.2"
            },
            {
                "text": "Normalizing: These four values can be scaled by any positive constant, and translated by any real constant, without affecting the optimal threshold or the utility (modulo that affine transform) (Gleave et al., 2021) . That is, we can choose a measurement scale for our utilities (without loss of generality) such that tp = 1 and fn = 0. Two degrees of freedom still remain (tn and fp). In most toolusing scenarios, tn will be extremely close to fn, because in both cases the immediate action by the agent is the same (do not execute) and thus has the same effect regardless of the predicted action. 5If we further assume (with loss of generality) that tn = fn = 0, the intuitive interpretation is that the agent gets 1 \"credit\" (an arbitrary utility unit) for completing its task, 0 credits for doing nothing (regardless of whether that was the best decision), and fp < 0 credits for doing something wrong. The single remaining degree of freedom fp is the risk/utility ratio, defining how costly it is to attempt and fail. In this (slightly less general) case, the MBR decision rule (2) simplifies to:",
                "cite_spans": [
                    {
                        "start": 194,
                        "end": 215,
                        "text": "(Gleave et al., 2021)",
                        "ref_id": "BIBREF14"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Expected Tool-Calling Utility (ETCU)",
                "sec_num": "3.2"
            },
            {
                "text": "EQUATION",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 0,
                        "end": 8,
                        "text": "EQUATION",
                        "ref_id": "EQREF",
                        "raw_str": "p > \u03c4 def = -fp 1 + -fp = fp fp -1",
                        "eq_num": "(3)"
                    }
                ],
                "section": "Expected Tool-Calling Utility (ETCU)",
                "sec_num": "3.2"
            },
            {
                "text": "Settings for expected tool-calling utility: To understand how confidence estimators perform at different risk levels, we choose three different values of fp under which to measure normalized risk (Table 1). Each setting of fp determines a threshold \u03c4 that the Bayes-optimal policy will use.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Expected Tool-Calling Utility (ETCU)",
                "sec_num": "3.2"
            },
            {
                "text": "High Risk: Tasks where executing an incorrect tool call is much worse than the reverse error. We choose fp = -9 for this setting, giving \u03c4 = 0.9.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Expected Tool-Calling Utility (ETCU)",
                "sec_num": "3.2"
            },
            {
                "text": "Medium Risk: For these tasks, executing an incorrect tool call is as bad as executing the correct tool call is good (fp = -tp = -1), giving \u03c4 = 0.5. Low Risk: These are tasks where executing an incorrect tool call has relatively low potential downside. We choose fp = -1 9 , giving \u03c4 = 0.1. Area Under Curve (AUC): More generally, we can compute an expected value for any \u03c4 \u2208 (0, 1). This yields an \"expected tool-calling utility\" curve (Figure 4 ) for a given confidence estimator on a given dataset. Any given applied setting may only be interested in a single \u03c4 along the curve. Still, to compare estimators overall, it may be useful to consolidate the curve into a single number, summarizing an estimator's performance across all risk levels. Taking inspiration from the area under the receiver operating characteristic (ROC) curve (Marcum, 1960), we take the average of the expected tool-calling utility values at every point along the curve, which can be regarded as the (signed) area under the curve (AUC). 6 Since our formulation sets tn = fn = 0, always abstaining gets a expected tool-calling utility score of 0 regardless of risk level, and thus an AUC of 0. Because utilities can be negative, AUC values can also be negative. This occurs when model is overconfident (due to poor calibration) in too many high-risk predictions.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 445,
                        "end": 446,
                        "text": "4",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Expected Tool-Calling Utility (ETCU)",
                "sec_num": "3.2"
            },
            {
                "text": "We now look at training MICE and using it at test time to measure both smooth expected calibration error (smECE) and expected tool-calling utility.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experiments",
                "sec_num": "4"
            },
            {
                "text": "Our experiments use the simulated trial-and-error (STE) dataset (Wang et al., 2024) . The dataset was synthetically generated by simulating plausible tool-using scenarios for a given API and using GPT3.5-turbo with execution feedback to identify (presumptively) correct tool calls.",
                "cite_spans": [
                    {
                        "start": 64,
                        "end": 83,
                        "text": "(Wang et al., 2024)",
                        "ref_id": "BIBREF46"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dataset",
                "sec_num": "4.1"
            },
            {
                "text": "The dataset consists of English-language queries that require calling 50 distinct APIs. For tool call generation, we few-shot prompt an off-the-shelf LLM with examples from a demonstration set consisting of 4,520 examples taken from the STE training set. An alternative would have been to fine-tune the LLM on this demonstration set.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dataset",
                "sec_num": "4.1"
            },
            {
                "text": "To train MICE, we use the rest of the STE training set, split into a training set of 1500 examples (30 from each API) and a validation set of 750 examples (15 from each API). We then evaluate MICE on STE's test set of 750 examples. In all cases, we label a generated tool call as correct if and only if it exactly matches the one given by STE.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Dataset",
                "sec_num": "4.1"
            },
            {
                "text": "Figure 4 : Expected tool-calling utility on the test set at varying risk levels. We include four trivial policies for reference: oracle executes only when the underlying model is correct (an upper bound); always abstain never executes, getting reward 0; always execute never abstains; and the base rate policy switches from always execute to always abstain when the risk level exceeds the base accuracy. All policies perform similarly at low risk levels, where always execute is close to optimal and hard to improve on. MICE models show clear improvements in the medium and high risk regimes.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 7,
                        "end": 8,
                        "text": "4",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Dataset",
                "sec_num": "4.1"
            },
            {
                "text": "We consider three LLMs: Llama3-8B-Instruct, Llama3.1-8B-Instruct, and Llama3.2-3B-Instruct (Dubey et al., 2024) . We build and evaluate a separate MICE classifier for each LLM.",
                "cite_spans": [
                    {
                        "start": 91,
                        "end": 111,
                        "text": "(Dubey et al., 2024)",
                        "ref_id": "BIBREF10"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "LLMs",
                "sec_num": "4.2"
            },
            {
                "text": "We run each LLM on our validation and test sets in an 8-shot in-context learning setting, following Wang et al. (2024) , using greedy decoding to generate the tool calls y. For each evaluation example, the 8 in-context learning examples are selected from our demonstration set according to the procedure of Wang et al. (2024) , which computes similarity to the evaluation example using SentenceBERT (Reimers and Gurevych, 2019) .",
                "cite_spans": [
                    {
                        "start": 100,
                        "end": 118,
                        "text": "Wang et al. (2024)",
                        "ref_id": "BIBREF46"
                    },
                    {
                        "start": 307,
                        "end": 325,
                        "text": "Wang et al. (2024)",
                        "ref_id": "BIBREF46"
                    },
                    {
                        "start": 399,
                        "end": 427,
                        "text": "(Reimers and Gurevych, 2019)",
                        "ref_id": "BIBREF33"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Settings",
                "sec_num": "4.3"
            },
            {
                "text": "We train a baseline or MICE regressor on the training set to predict whether tool calls are correct, and use the validation set for hyperparameter and model selection. Features used by MICE regressors were described in \u00a72. We then evaluate the regressor on the test set, using the metrics of \u00a73.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Experimental Settings",
                "sec_num": "4.3"
            },
            {
                "text": "Raw Confidence Our first baseline is the raw confidence score from \u00a72, which can be used directly as a confidence estimate p. Recall that we defined this as i\u2208S p(w i |w <i ), where S is the subset of token indices that are relevant to the tool call. S omits the tokens associated with formatting (\"action:\" and \"action input:\", which are generated for every tool call), and also omits tokens that are generated after the arguments of the tool call. We observed in initial experiments that including these irrelevant tokens resulted in worse calibration. We also observed that taking the minimum probability across generated tokens instead of the joint probability (as in Zhou et al. (2022) ; Stengel-Eskin and Van Durme (2023a)) resulted in little effective difference. Note that calculating raw confidence does not require any learning, so neither the training nor validation set is used. Raw confidence is also used as a base feature in the estimators described below.",
                "cite_spans": [
                    {
                        "start": 672,
                        "end": 690,
                        "text": "Zhou et al. (2022)",
                        "ref_id": "BIBREF57"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "MICE Configurations & Baselines",
                "sec_num": "4.4"
            },
            {
                "text": "Histogram Regression Estimator (HRE; Nobel, 1996) For our second (stronger) baseline, we use a standard method to calibrate the previous baseline. We use the training set to construct a histogram binned by raw confidence scores. We use 25 bins: [0, 0.04), [0.04, 0.08), . . . , [0.96, 1.0]. To map from a raw confidence score c to a recalibrated estimate p, we look up c's bin, and return the percentage of examples in that bin that are correct. Note that this is the same histogram construction used to calculate traditional ECE (except here constructed on the training set), and so should be expected to perform well on ECE metrics.",
                "cite_spans": [
                    {
                        "start": 37,
                        "end": 49,
                        "text": "Nobel, 1996)",
                        "ref_id": "BIBREF29"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "MICE Configurations & Baselines",
                "sec_num": "4.4"
            },
            {
                "text": "Kernel Regressor (NWKR) Here, rather than using a histogram with fixed bins to recalibrate, we use Nadaraya-Watson kernel regression (Nadaraya, 1964; Watson, 1964) , following the exact procedure B\u0142asiok and Nakkiran (2024) used to compute smECE. Analogously to above, since this follows the exact same procedure as in smECE, we should expect it to perform well under that metric. 7 MICE Models We extract features as described in \u00a72, using DeBERTa-xlarge-mnli to compute the BERTScore features as it is the strongest BERTScore base model (He et al., 2021) . This gives \u2113 -1 BERTScore features along with the raw confidence feature. There are \u2113 = 32 layers for Llama3 and 3.1 and 28 layers for Llama3.2.",
                "cite_spans": [
                    {
                        "start": 133,
                        "end": 149,
                        "text": "(Nadaraya, 1964;",
                        "ref_id": "BIBREF25"
                    },
                    {
                        "start": 150,
                        "end": 163,
                        "text": "Watson, 1964)",
                        "ref_id": "BIBREF50"
                    },
                    {
                        "start": 196,
                        "end": 223,
                        "text": "B\u0142asiok and Nakkiran (2024)",
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 539,
                        "end": 556,
                        "text": "(He et al., 2021)",
                        "ref_id": "BIBREF17"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "MICE Configurations & Baselines",
                "sec_num": "4.4"
            },
            {
                "text": "MICE Logistic Regressor (MICE LR): We train a logistic regression model with an L2 regularization strength of 2 to predict whether the tool call is correct or not.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "MICE Configurations & Baselines",
                "sec_num": "4.4"
            },
            {
                "text": "MICE Random Forest (MICE RF): We train a random forest classifier using 1000 trees each with a maximum depth of 20 and a maximum of 10 features to use at each split, using the Scikit-Learn package (Pedregosa et al., 2011) . Other hyperparameters are set to defaults. This model is also trained to predict whether the tool call is correct. 8",
                "cite_spans": [
                    {
                        "start": 197,
                        "end": 221,
                        "text": "(Pedregosa et al., 2011)",
                        "ref_id": "BIBREF31"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "MICE Configurations & Baselines",
                "sec_num": "4.4"
            },
            {
                "text": "Smooth Expected Calibration Error Lower smECE is better. The first numeric column of Table 1 shows that all of the confidence estimators are well-calibrated-their smECE values are small and not significantly different-except for the raw confidences, which have smECEs 3-10x higher than the others. This is not surprising: HRE and NWKR are explicitly designed to calibrate the raw confidences, while logistic regression and random forest training are known to produce well-calibrated classifiers (Niculescu-Mizil and Caruana, 2005) .",
                "cite_spans": [
                    {
                        "start": 495,
                        "end": 530,
                        "text": "(Niculescu-Mizil and Caruana, 2005)",
                        "ref_id": "BIBREF28"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 91,
                        "end": 92,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5"
            },
            {
                "text": "Expected Tool-Calling Utility Figure 4 shows the expected tool-calling utility curve for each confidence estimator and each model. We find that raw confidence performs dangerously poorly at and above moderate risk levels. HRE and NWKR both degrade quickly toward 0 as risk increases. The MICE models also degrade, but more slowly: matching performance of HRE and NWKR at the lower risk levels and outperforming at medium and 7 HRE and NWKR learn to map a single confidence input feature to a recalibrated output confidence. Any confidence estimator can be calibrated in this way on held-out data. Other common approaches to this problem include isotonic regression and Platt scaling ( \u00a77).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 37,
                        "end": 38,
                        "text": "4",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5"
            },
            {
                "text": "8 Note that HRE and MICE LR use a similar number of parameters, but in HRE they are devoted to closer analysis (binning) of the raw confidence dimension, rather than to additional BERTScore dimensions. higher risk levels. Across all three LLMs, MICE RF performs best at nearly every risk level.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5"
            },
            {
                "text": "Table 1 displays how well confidence estimators perform at three specific risk level settings (low, medium, and high) and across the full range of risk levels using AUC (see \u00a73.2). For all of these metrics, a higher score is better. For each risk level, MICE RF always has the highest reward, outperforming HRE, NWKR, and MICE LR. Raw token confidence nearly always performs worst. For lower risk levels, most strategies perform comparably, with relatively high reward. This is expected: executing an incorrect tool call (fp) gives a low penalty relative to a correct tool (tp), so aggressively biasing for execution is optimal, garnering a high reward. As risk levels increase, the penalty for executing an incorrect tool call grows and using raw confidences nearly always incurs a negative reward when the risk level is greater than 0.5 (fp < -1). Across the three risk levels, we find that the MICE models outperform both baselines for each of the three tool-calling LLM agents.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 6,
                        "end": 7,
                        "text": "1",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5"
            },
            {
                "text": "We run permutation tests for each metric in Table 1 for each MICE method as compared to HRE and NWKR. In summary, MICE RF is always significant (p-value < 0.05) at the medium risk level, never significant at the low risk level, and significant at the high risk level for Llama3 and 3.1, but not 3.2. MICE LR outperforms the baselines, but is only significant for the medium risk level for Llama3.1. For the summary statistic AUC-ETCU, both MICE models are nearly always significantly better than HRE and NWKR for all three Llamas.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Results",
                "sec_num": "5"
            },
            {
                "text": "To test MICE's out-of-domain generalization, we simulate encountering new APIs by holding one out during training. Since there are 50 APIs present in the STE dataset, we train 50 MICE RF and 50 MICE LR models. Each model is trained on data from 49 APIs and evaluated solely on the held-out API. We combine the predictions from each of the models to get predictions across the entire test set.9 These confidence estimates are solely constructed by MICE models that have never seen that specific API before, so every tool is unseen. MICE does worse in this setting, but only degrades to the level of HRE and NWKR models trained on the full data; they are statistically indistinguishable from them. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Zero-Shot Generalization to New APIs",
                "sec_num": null
            },
            {
                "text": "What is generated by decoding from intermediate layers? Here, we look at what the LLM generates from intermediary layers. Using the logit lens, we find that models slowly evolve their predictions throughout the layers to get closer to the final output generation. Figure 2 shows sample generations. Qualitatively, the first two-thirds of the layers tend to generate seemingly random strings. After this point, the generations get increasingly closer to the final generation, but significant refinement still occurs in the final layer.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 271,
                        "end": 272,
                        "text": "2",
                        "ref_id": "FIGREF1"
                    }
                ],
                "eq_spans": [],
                "section": "Analysis",
                "sec_num": "6"
            },
            {
                "text": "The box-and-whisker plot in Figure 3 shows that BERTScore tends to increase with layer number. Figure 8 in Appendix A shows that at some layers, the distribution of BERTScores tends to be shifted slightly higher on correct outputs, providing signal to the classifier.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 35,
                        "end": 36,
                        "text": "3",
                        "ref_id": null
                    },
                    {
                        "start": 102,
                        "end": 103,
                        "text": "8",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Analysis",
                "sec_num": "6"
            },
            {
                "text": "What is learned? To better understand how the MICE features are used, we examine our MICE models trained on the STE dataset with Llama3-8B-Instruct. For MICE RF we calculate Gini coefficients, and for MICE LR we analyze the feature weights, as suggested by reviewers. Figures 5 and 6 indicate that confidence is the most important feature in both MICE models: roughly 3 times as important as other features in MICE RF and 2 times as important as other features in MICE LR. 10 There is no obvious other pattern in the estimated weights, and it is possible that they are underdetermined.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 276,
                        "end": 277,
                        "text": "5",
                        "ref_id": "FIGREF2"
                    },
                    {
                        "start": 282,
                        "end": 283,
                        "text": "6",
                        "ref_id": "FIGREF3"
                    }
                ],
                "eq_spans": [],
                "section": "Analysis",
                "sec_num": "6"
            },
            {
                "text": "To better understand which features contribute most to confidence estimation, we performed feature ablations for both MICE models for the three LLMs in our study. In addition to the original setting with all features, we tested four new settings: confidence only; 11 first 10 Perhaps calibrated confidence would have worked even better as a feature.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Feature Ablations",
                "sec_num": null
            },
            {
                "text": "11 For LR, this is exactly Platt scaling with L2 regularization. half of the layers' BERTScores plus confidence; second half of the layers' BERTScores plus confidence; and all of the layers' BERTScores, but no confidence. See Table 2 in Appendix A for details. MICE RF: Confidence alone performed extremely poorly. The second half of the layers plus confidence performed better than the first half plus confidence, but using all layers without confidence performed worse than using half the layers with confidence. This suggests that features from the second half of the model are more useful than the first half, and confidence is an important feature.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 232,
                        "end": 233,
                        "text": "2",
                        "ref_id": null
                    }
                ],
                "eq_spans": [],
                "section": "Feature Ablations",
                "sec_num": null
            },
            {
                "text": "MICE LR: Confidence alone performed comparably to other settings, indicating that confidence accounts for much of the performance; unlike RF, LR learned how to use this feature. Additionally, for Llama3 and 3.1, using confidence alone outperformed using all the layers' BERTScore features. Using the second half of the layers' BERTScore features outperformed using the first half of the layers' features, similar to MICE RF.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Feature Ablations",
                "sec_num": null
            },
            {
                "text": "To measure sample efficiency, we vary the size of the training set to be 25, 50, 75, 100, 300, 500, and 750. For each size, we randomly partition the 1,500 training examples into disjoint groups of that size (e.g., 15 groups of 100 examples, or 3 groups of 500 examples). We then train on each group, measure AUC-ETCU, and compute the mean and variance across groups. We repeat this 100 times and average across trials, plotting results in Figure 7 .",
                "cite_spans": [
                    {
                        "start": 73,
                        "end": 108,
                        "text": "25, 50, 75, 100, 300, 500, and 750.",
                        "ref_id": null
                    }
                ],
                "ref_spans": [
                    {
                        "start": 447,
                        "end": 448,
                        "text": "7",
                        "ref_id": "FIGREF4"
                    }
                ],
                "eq_spans": [],
                "section": "How sample efficient is MICE?",
                "sec_num": null
            },
            {
                "text": "For dataset sizes of 150 or below NWKR performs best, but it saturates at this level and does not improve further with more data. MICE LR and HRE perform poorly with small datasets, but as size increases, they get closer to MICE RF and NWKR. For larger dataset sizes, MICE RF and MICE LR overtake NWKR. In fact, with as few as 300 examples (20% of the training data), MICE RF outperforms NWKR trained on the full dataset.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "How sample efficient is MICE?",
                "sec_num": null
            },
            {
                "text": "Model Internals Tenney et al. (2019) show that different layers of models encode different aspects of the classical NLP pipeline. Moreover, intermediate layer activations can be nudged via steering vectors to control output generations (Subramani et al., 2019 (Subramani et al., , 2022;; Turner et al., 2023) . The activation spaces of models are relatively well-formed and there exist directions in these latent spaces that correlate with interpretable properties (Subramani and Suresh, 2020; Li et al., 2024) . These act as part of the basis for our hypothesis that the model internals could contain a trustworthiness signal, although we did not attempt to discover specific directions in these spaces.",
                "cite_spans": [
                    {
                        "start": 16,
                        "end": 36,
                        "text": "Tenney et al. (2019)",
                        "ref_id": "BIBREF44"
                    },
                    {
                        "start": 236,
                        "end": 259,
                        "text": "(Subramani et al., 2019",
                        "ref_id": "BIBREF40"
                    },
                    {
                        "start": 260,
                        "end": 287,
                        "text": "(Subramani et al., , 2022;;",
                        "ref_id": "BIBREF42"
                    },
                    {
                        "start": 288,
                        "end": 308,
                        "text": "Turner et al., 2023)",
                        "ref_id": "BIBREF45"
                    },
                    {
                        "start": 465,
                        "end": 493,
                        "text": "(Subramani and Suresh, 2020;",
                        "ref_id": "BIBREF41"
                    },
                    {
                        "start": 494,
                        "end": 510,
                        "text": "Li et al., 2024)",
                        "ref_id": "BIBREF21"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work",
                "sec_num": "7"
            },
            {
                "text": "We can view language models with multiple layers as doing iterative inference, where each successive layer refines the predictions of the previous layer. With this lens, decoding from intermediate layers provides signal albeit noisy: the first half of the layers generate uninterpretable text, but after this predictions refine toward a plausible answer (Belrose et al., 2023; Yom Din et al., 2024; Merullo et al., 2024) . Other work has focused on inference efficiency by early exiting from transformers (Teerapittayanon et al., 2017; Geva et al., 2022; Schuster et al., 2022; Elhoushi et al., 2024) . Our work decodes from intermediary layers as a signal for better calibration.",
                "cite_spans": [
                    {
                        "start": 354,
                        "end": 376,
                        "text": "(Belrose et al., 2023;",
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 377,
                        "end": 398,
                        "text": "Yom Din et al., 2024;",
                        "ref_id": "BIBREF53"
                    },
                    {
                        "start": 399,
                        "end": 420,
                        "text": "Merullo et al., 2024)",
                        "ref_id": "BIBREF23"
                    },
                    {
                        "start": 505,
                        "end": 535,
                        "text": "(Teerapittayanon et al., 2017;",
                        "ref_id": "BIBREF43"
                    },
                    {
                        "start": 536,
                        "end": 554,
                        "text": "Geva et al., 2022;",
                        "ref_id": "BIBREF13"
                    },
                    {
                        "start": 555,
                        "end": 577,
                        "text": "Schuster et al., 2022;",
                        "ref_id": "BIBREF36"
                    },
                    {
                        "start": 578,
                        "end": 600,
                        "text": "Elhoushi et al., 2024)",
                        "ref_id": "BIBREF11"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Intermediate Decoding",
                "sec_num": null
            },
            {
                "text": "Calibration Prior work has measured the calibration of off-the-shelf models, including neural networks (Niculescu-Mizil and Caruana, 2005; Wang, 2024) , large language models (Kadavath et al., 2022; Yin et al., 2023) , and semantic parsers (Stengel-Eskin and Van Durme, 2023a; Zhou et al., 2022) .",
                "cite_spans": [
                    {
                        "start": 103,
                        "end": 138,
                        "text": "(Niculescu-Mizil and Caruana, 2005;",
                        "ref_id": "BIBREF28"
                    },
                    {
                        "start": 139,
                        "end": 150,
                        "text": "Wang, 2024)",
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 175,
                        "end": 198,
                        "text": "(Kadavath et al., 2022;",
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 199,
                        "end": 216,
                        "text": "Yin et al., 2023)",
                        "ref_id": null
                    },
                    {
                        "start": 240,
                        "end": 276,
                        "text": "(Stengel-Eskin and Van Durme, 2023a;",
                        "ref_id": null
                    },
                    {
                        "start": 277,
                        "end": 295,
                        "text": "Zhou et al., 2022)",
                        "ref_id": "BIBREF57"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Intermediate Decoding",
                "sec_num": null
            },
            {
                "text": "A line of machine learning work focuses on calibrating binary classifiers while conditioning only on their predicted confidence. Platt scaling transforms a real-valued output (like that of an SVM classifier) into probabilities using logistic regression (Platt, 1999) , which is proven to be equivalent to beta calibration up to preprocessing (B\u00f6ken, 2021) . Isotonic regression (Ayer et al., 1955) is a non-parametric approach that learns a best fit to data making only a monotonic non-decreasing assumption. HREs are popular, and there has been work on adaptive binning strategies (Nobel, 1996) . We chose HRE and NWKR as strong baselines from this class of models. MICE LR could be viewed as an extension to Platt scaling because MICE conditions on model internals in addition to the original confidence.",
                "cite_spans": [
                    {
                        "start": 253,
                        "end": 266,
                        "text": "(Platt, 1999)",
                        "ref_id": "BIBREF32"
                    },
                    {
                        "start": 342,
                        "end": 355,
                        "text": "(B\u00f6ken, 2021)",
                        "ref_id": "BIBREF6"
                    },
                    {
                        "start": 378,
                        "end": 397,
                        "text": "(Ayer et al., 1955)",
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 582,
                        "end": 595,
                        "text": "(Nobel, 1996)",
                        "ref_id": "BIBREF29"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Intermediate Decoding",
                "sec_num": null
            },
            {
                "text": "The DidYouMean system can rephrase a query and ask for confirmation when the model is unconfident (Stengel-Eskin and Van Durme, 2023b). Like us, they frame the competing concerns in terms of safety and utility, weighing wrongly predicted actions against the cost of asking clarifying questions. While they tune a single confidence threshold, we transform confidences into calibrated probabilities so that a Bayes-optimal threshold can be dynamically derived for any risk/reward ratio. LA-CIE (Stengel-Eskin et al., 2024) communicates its fine-tuned confidences to users. APEL (Zhong et al., 2023) reduces its uncertainty about a semantic parse by asking questions of a user, using raw confidences to identify informative questions; calibrated confidences should work better, allowing it to finish with fewer questions.",
                "cite_spans": [
                    {
                        "start": 492,
                        "end": 520,
                        "text": "(Stengel-Eskin et al., 2024)",
                        "ref_id": "BIBREF37"
                    },
                    {
                        "start": 576,
                        "end": 596,
                        "text": "(Zhong et al., 2023)",
                        "ref_id": "BIBREF56"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Applications of Well-Calibrated Confidences",
                "sec_num": null
            },
            {
                "text": "In this work, we introduce model-internal confidence estimators (MICE), which improve the trustworthiness and safety of language models as toolcalling agents. We introduce a new metric, expected tool-calling utility, that combines calibration and usefulness to better evaluate the safety and utility of tool calls. We show that MICE matches or beats both regression baselines (HRE and NWKR) when measured by smooth ECE, and significantly improves expected tool-calling utility, especially in medium and high-risk regimes. Finally, we find that MICE is sample efficient and can generalize to unseen APIs in a zero-shot setting.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "8"
            },
            {
                "text": "Like logit lens, MICE assumes transformer language model whose intermediate layers have the same shape as the final layer. More generally, MICE requires access to model internals, ruling out some of the most capable current LLMs, which are closed.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "8"
            },
            {
                "text": "In principle, MICE is a general-purpose confidence estimation recipe for transformer language models. However, we evaluated MICE exclusively in one setting: a tool-calling task on one dataset. Other settings such as machine translation and question answering (see footnote 1) have been left to future experiments.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "8"
            },
            {
                "text": "As footnote 3 hinted, there are many other possible ways to compute MICE features. We do not claim to have found the best variant even for the setting we studied. While we settled on BERTScore for this paper, there are several other possible choices for how to encode, align, compare, and aggregate the tokens at each layer. We remark that one possible encoding trick would be to learn a linear transform of each layer i so that h (i) t-1 is maximally similar to h (\u2113) t-1 or maximally predictive of y t , as in the tuned lens of (Belrose et al., 2023) .",
                "cite_spans": [
                    {
                        "start": 530,
                        "end": 552,
                        "text": "(Belrose et al., 2023)",
                        "ref_id": "BIBREF2"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "8"
            },
            {
                "text": "There are also various ways to build a classifier that uses MICE features. We also experimented with SVMs with different kernels (not reported). Other options could also be tried.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Conclusion",
                "sec_num": "8"
            },
            {
                "text": "Better calibrated models can help people make safer decisions. We hope to bring increased focus to risk/reward tradeoffs; we have intentionally framed the task and metric in a way that highlights the cost of false positives. Decision theory and reward functions are not a substitute for careful design, however; practitioners must exercise great care before hooking up an LLM to a tool with real effects in the world, including taking care to set appropriate rewards such as tp, fp, tn, fn.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Impact Statement",
                "sec_num": "10"
            },
            {
                "text": "We train and test confidence estimators specifically on the generation of tool calls-a new setting for confidence estimation. However, MICE could equally well be applied to well-studied confidence estimation settings in NLP, such as machine translation(Blatz et al.,",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "2004;Kumar and Sarawagi, 2019;Wang et al., 2020), long-form generation(Band et al., 2024), and semantic parsing(Stengel-Eskin and Van Durme, 2023a).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "Note that taking i = \u2113 in (1) would recover y. Because the transformer uses residual connections, each layerwise encoding h (i)t-1 has the same dimensionality d, so multiplication by the unembedding matrix Woutis defined even when i < \u2113. All of these vector-matrix products can be computed in parallel by a matrix-matrix product, H(i) Wout where H (i) \u2208 R \u2113\u00d7d .",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "3 BERTScore reencodes the strings y and y(i) with a separate model (see \u00a74.4) and aligns their tokens. We found that the alignments were not always trivial. BERTscore performed significantly better than methods we explored initially, which compared the softmax(h(i)t-1 Wout) distributions rather than argmax-decoding single strings y(i) . See \u00a79 for other options.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "tn might differ from fn because subsequent actions may diverge, and each utility should ideally include the expected future reward over all possible rollouts. For example, it might be slightly easier to ask clarifying questions when the original prediction was correct (implying fn > tn and raising \u03c4 ).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "In practice, we approximate AUC by evaluating expected tool-calling utility at each \u03c4 \u2208 {0.001, 0.002, . . . , 0.999}.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            },
            {
                "text": "This resembles 50-fold cross validation, where each fold is constructed solely with data from one API. However, for comparability with other methods, we evaluate on the corresponding fold in the test set, not the training set.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": null
            }
        ],
        "back_matter": [
            {
                "text": " (Wang et al., 2024) . Lower smECE is better, while higher tool-calling utility is better. Bold indicates the best result in each category and underline indicates the second best result in each category. ",
                "cite_spans": [
                    {
                        "start": 1,
                        "end": 20,
                        "text": "(Wang et al., 2024)",
                        "ref_id": "BIBREF46"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "annex",
                "sec_num": null
            }
        ],
        "bib_entries": {
            "BIBREF0": {
                "ref_id": "b0",
                "title": "An empirical distribution function for sampling with incomplete information",
                "authors": [
                    {
                        "first": "Miriam",
                        "middle": [
                            "C"
                        ],
                        "last": "Ayer",
                        "suffix": ""
                    },
                    {
                        "first": "Hugh",
                        "middle": [
                            "D"
                        ],
                        "last": "Brunk",
                        "suffix": ""
                    },
                    {
                        "first": "George",
                        "middle": [
                            "M"
                        ],
                        "last": "Ewing",
                        "suffix": ""
                    },
                    {
                        "first": "W",
                        "middle": [
                            "T"
                        ],
                        "last": "Reid",
                        "suffix": ""
                    },
                    {
                        "first": "Edward",
                        "middle": [],
                        "last": "Silverman",
                        "suffix": ""
                    }
                ],
                "year": 1955,
                "venue": "Annals of Mathematical Statistics",
                "volume": "26",
                "issue": "",
                "pages": "641--647",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Miriam C. Ayer, Hugh D. Brunk, George M. Ewing, W. T. Reid, and Edward Silverman. 1955. An empir- ical distribution function for sampling with incom- plete information. Annals of Mathematical Statistics, 26:641-647.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "b1",
                "title": "Linguistic calibration of longform generations",
                "authors": [
                    {
                        "first": "Neil",
                        "middle": [],
                        "last": "Band",
                        "suffix": ""
                    },
                    {
                        "first": "Xuechen",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Tengyu",
                        "middle": [],
                        "last": "Ma",
                        "suffix": ""
                    },
                    {
                        "first": "Tatsunori",
                        "middle": [],
                        "last": "Hashimoto",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "Forty-first International Conference on Machine Learning",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Neil Band, Xuechen Li, Tengyu Ma, and Tatsunori Hashimoto. 2024. Linguistic calibration of long- form generations. In Forty-first International Confer- ence on Machine Learning.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "b2",
                "title": "Eliciting latent predictions from transformers with the tuned lens",
                "authors": [
                    {
                        "first": "Nora",
                        "middle": [],
                        "last": "Belrose",
                        "suffix": ""
                    },
                    {
                        "first": "Zach",
                        "middle": [],
                        "last": "Furman",
                        "suffix": ""
                    },
                    {
                        "first": "Logan",
                        "middle": [],
                        "last": "Smith",
                        "suffix": ""
                    },
                    {
                        "first": "Danny",
                        "middle": [],
                        "last": "Halawi",
                        "suffix": ""
                    },
                    {
                        "first": "Igor",
                        "middle": [
                            "V"
                        ],
                        "last": "Ostrovsky",
                        "suffix": ""
                    },
                    {
                        "first": "Lev",
                        "middle": [],
                        "last": "Mckinney",
                        "suffix": ""
                    },
                    {
                        "first": "Stella",
                        "middle": [],
                        "last": "Biderman",
                        "suffix": ""
                    },
                    {
                        "first": "Jacob",
                        "middle": [],
                        "last": "Steinhardt",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nora Belrose, Zach Furman, Logan Smith, Danny Ha- lawi, Igor V. Ostrovsky, Lev McKinney, Stella Bi- derman, and Jacob Steinhardt. 2023. Eliciting latent predictions from transformers with the tuned lens. ArXiv, abs/2303.08112.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "b3",
                "title": "Mathematical Statistics: Basic Ideas and Selected Topics",
                "authors": [
                    {
                        "first": "Peter",
                        "middle": [],
                        "last": "Bickel",
                        "suffix": ""
                    },
                    {
                        "first": "Kjell",
                        "middle": [],
                        "last": "Doksum",
                        "suffix": ""
                    }
                ],
                "year": 1977,
                "venue": "",
                "volume": "56",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "DOI": [
                        "10.2307/2286373"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Peter Bickel and Kjell Doksum. 1977. Mathematical Statistics: Basic Ideas and Selected Topics., vol- ume 56. Holden-Day Inc.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "b4",
                "title": "Smooth ECE: Principled reliability diagrams via kernel smoothing",
                "authors": [
                    {
                        "first": "Jaros\u0142aw",
                        "middle": [],
                        "last": "B\u0142asiok",
                        "suffix": ""
                    },
                    {
                        "first": "Preetum",
                        "middle": [],
                        "last": "Nakkiran",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "The Twelfth International Conference on Learning Representations",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Jaros\u0142aw B\u0142asiok and Preetum Nakkiran. 2024. Smooth ECE: Principled reliability diagrams via kernel smoothing. In The Twelfth International Conference on Learning Representations.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "b5",
                "title": "Confidence estimation for machine translation",
                "authors": [
                    {
                        "first": "John",
                        "middle": [],
                        "last": "Blatz",
                        "suffix": ""
                    },
                    {
                        "first": "Erin",
                        "middle": [],
                        "last": "Fitzgerald",
                        "suffix": ""
                    },
                    {
                        "first": "George",
                        "middle": [],
                        "last": "Foster",
                        "suffix": ""
                    },
                    {
                        "first": "Simona",
                        "middle": [],
                        "last": "Gandrabur",
                        "suffix": ""
                    },
                    {
                        "first": "Cyril",
                        "middle": [],
                        "last": "Goutte",
                        "suffix": ""
                    },
                    {
                        "first": "Alex",
                        "middle": [],
                        "last": "Kulesza",
                        "suffix": ""
                    },
                    {
                        "first": "Alberto",
                        "middle": [],
                        "last": "Sanchis",
                        "suffix": ""
                    },
                    {
                        "first": "Nicola",
                        "middle": [],
                        "last": "Ueffing",
                        "suffix": ""
                    }
                ],
                "year": 2004,
                "venue": "COLING 2004: Proceedings of the 20th International Conference on Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "315--321",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "John Blatz, Erin Fitzgerald, George Foster, Simona Gan- drabur, Cyril Goutte, Alex Kulesza, Alberto Sanchis, and Nicola Ueffing. 2004. Confidence estimation for machine translation. In COLING 2004: Pro- ceedings of the 20th International Conference on Computational Linguistics, pages 315-321, Geneva, Switzerland. COLING.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "b6",
                "title": "On the appropriateness of Platt scaling in classifier calibration",
                "authors": [
                    {
                        "first": "Bj\u00f6rn",
                        "middle": [],
                        "last": "B\u00f6ken",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "Information Systems",
                "volume": "95",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "DOI": [
                        "10.1016/j.is.2020.101641"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Bj\u00f6rn B\u00f6ken. 2021. On the appropriateness of Platt scaling in classifier calibration. Information Systems, 95:101641.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "b7",
                "title": "Deep reinforcement learning from human preferences. Advances in Neural Information Processing Systems",
                "authors": [
                    {
                        "first": "Jan",
                        "middle": [],
                        "last": "Paul F Christiano",
                        "suffix": ""
                    },
                    {
                        "first": "Tom",
                        "middle": [],
                        "last": "Leike",
                        "suffix": ""
                    },
                    {
                        "first": "Miljan",
                        "middle": [],
                        "last": "Brown",
                        "suffix": ""
                    },
                    {
                        "first": "Shane",
                        "middle": [],
                        "last": "Martic",
                        "suffix": ""
                    },
                    {
                        "first": "Dario",
                        "middle": [],
                        "last": "Legg",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Amodei",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Paul F Christiano, Jan Leike, Tom Brown, Miljan Mar- tic, Shane Legg, and Dario Amodei. 2017. Deep reinforcement learning from human preferences. Ad- vances in Neural Information Processing Systems, 30.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "b8",
                "title": "The well-calibrated Bayesian",
                "authors": [
                    {
                        "first": "A",
                        "middle": [
                            "Philip"
                        ],
                        "last": "Dawid",
                        "suffix": ""
                    }
                ],
                "year": 1982,
                "venue": "Journal of the American Statistical Association",
                "volume": "77",
                "issue": "",
                "pages": "605--610",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "A. Philip Dawid. 1982. The well-calibrated Bayesian. Journal of the American Statistical Association, 77:605-610.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "b9",
                "title": "Calibration of pre-trained transformers",
                "authors": [
                    {
                        "first": "Shrey",
                        "middle": [],
                        "last": "Desai",
                        "suffix": ""
                    },
                    {
                        "first": "Greg",
                        "middle": [],
                        "last": "Durrett",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "volume": "",
                "issue": "",
                "pages": "295--302",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2020.emnlp-main.21"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Shrey Desai and Greg Durrett. 2020. Calibration of pre-trained transformers. In Proceedings of the 2020 Conference on Empirical Methods in Natural Lan- guage Processing (EMNLP), pages 295-302, Online. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "b10",
                "title": "The Llama 3 herd of models",
                "authors": [
                    {
                        "first": "Abhimanyu",
                        "middle": [],
                        "last": "Dubey",
                        "suffix": ""
                    },
                    {
                        "first": "Abhinav",
                        "middle": [],
                        "last": "Jauhri",
                        "suffix": ""
                    },
                    {
                        "first": "Abhinav",
                        "middle": [],
                        "last": "Pandey",
                        "suffix": ""
                    },
                    {
                        "first": "Abhishek",
                        "middle": [],
                        "last": "Kadian",
                        "suffix": ""
                    },
                    {
                        "first": "Ahmad",
                        "middle": [],
                        "last": "Al-Dahle",
                        "suffix": ""
                    },
                    {
                        "first": "Aiesha",
                        "middle": [],
                        "last": "Letman",
                        "suffix": ""
                    },
                    {
                        "first": "Akhil",
                        "middle": [],
                        "last": "Mathur",
                        "suffix": ""
                    },
                    {
                        "first": "Alan",
                        "middle": [],
                        "last": "Schelten",
                        "suffix": ""
                    },
                    {
                        "first": "Amy",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Angela",
                        "middle": [],
                        "last": "Fan",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2407.21783"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. 2024. The Llama 3 herd of models. arXiv preprint arXiv:2407.21783.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "b11",
                "title": "Layer skip: Enabling early exit inference and self-speculative decoding",
                "authors": [
                    {
                        "first": "Mostafa",
                        "middle": [],
                        "last": "Elhoushi",
                        "suffix": ""
                    },
                    {
                        "first": "Akshat",
                        "middle": [],
                        "last": "Shrivastava",
                        "suffix": ""
                    },
                    {
                        "first": "Diana",
                        "middle": [],
                        "last": "Liskovich",
                        "suffix": ""
                    },
                    {
                        "first": "Basil",
                        "middle": [],
                        "last": "Hosmer",
                        "suffix": ""
                    },
                    {
                        "first": "Bram",
                        "middle": [],
                        "last": "Wasti",
                        "suffix": ""
                    },
                    {
                        "first": "Liangzhen",
                        "middle": [],
                        "last": "Lai",
                        "suffix": ""
                    },
                    {
                        "first": "Anas",
                        "middle": [],
                        "last": "Mahmoud",
                        "suffix": ""
                    },
                    {
                        "first": "Bilge",
                        "middle": [],
                        "last": "Acun",
                        "suffix": ""
                    },
                    {
                        "first": "Saurabh",
                        "middle": [],
                        "last": "Agarwal",
                        "suffix": ""
                    },
                    {
                        "first": "Ahmed",
                        "middle": [],
                        "last": "Roman",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2404.16710"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Mostafa Elhoushi, Akshat Shrivastava, Diana Liskovich, Basil Hosmer, Bram Wasti, Liangzhen Lai, Anas Mahmoud, Bilge Acun, Saurabh Agarwal, Ahmed Roman, et al. 2024. Layer skip: Enabling early exit inference and self-speculative decoding. arXiv preprint arXiv:2404.16710.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "b12",
                "title": "Detecting hallucinations in large language models using semantic entropy",
                "authors": [
                    {
                        "first": "Sebastian",
                        "middle": [],
                        "last": "Farquhar",
                        "suffix": ""
                    },
                    {
                        "first": "Jannik",
                        "middle": [],
                        "last": "Kossen",
                        "suffix": ""
                    },
                    {
                        "first": "Lorenz",
                        "middle": [],
                        "last": "Kuhn",
                        "suffix": ""
                    },
                    {
                        "first": "Yarin",
                        "middle": [],
                        "last": "Gal",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "Nature",
                "volume": "630",
                "issue": "8017",
                "pages": "625--630",
                "other_ids": {
                    "DOI": [
                        "10.1038/s41586-024-07421-0"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Sebastian Farquhar, Jannik Kossen, Lorenz Kuhn, and Yarin Gal. 2024. Detecting hallucinations in large language models using semantic entropy. Nature, 630(8017):625-630.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "b13",
                "title": "Transformer feed-forward layers build predictions by promoting concepts in the vocabulary space",
                "authors": [
                    {
                        "first": "Mor",
                        "middle": [],
                        "last": "Geva",
                        "suffix": ""
                    },
                    {
                        "first": "Avi",
                        "middle": [],
                        "last": "Caciularu",
                        "suffix": ""
                    },
                    {
                        "first": "Kevin",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Goldberg",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "30--45",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2022.emnlp-main.3"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Mor Geva, Avi Caciularu, Kevin Wang, and Gold- berg. 2022. Transformer feed-forward layers build predictions by promoting concepts in the vocabulary space. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Process- ing, pages 30-45, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "b14",
                "title": "Quantifying differences in reward functions",
                "authors": [
                    {
                        "first": "Adam",
                        "middle": [],
                        "last": "Gleave",
                        "suffix": ""
                    },
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Michael",
                        "suffix": ""
                    },
                    {
                        "first": "Shane",
                        "middle": [],
                        "last": "Dennis",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Legg",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "International Conference on Learning Representations",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Adam Gleave, Michael D Dennis, Shane Legg, Stuart Russell, and Jan Leike. 2021. Quantifying differ- ences in reward functions. In International Confer- ence on Learning Representations.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "b15",
                "title": "On calibration of modern neural networks",
                "authors": [
                    {
                        "first": "Chuan",
                        "middle": [],
                        "last": "Guo",
                        "suffix": ""
                    },
                    {
                        "first": "Geoff",
                        "middle": [],
                        "last": "Pleiss",
                        "suffix": ""
                    },
                    {
                        "first": "Yu",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    },
                    {
                        "first": "Kilian",
                        "middle": [
                            "Q"
                        ],
                        "last": "Weinberger",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Wein- berger. 2017. On calibration of modern neural net- works. Preprint, arxiv:1706.04599 [cs].",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "b16",
                "title": "LLM-Rubric: A multidimensional, calibrated approach to automated evaluation of natural language texts",
                "authors": [
                    {
                        "first": "Helia",
                        "middle": [],
                        "last": "Hashemi",
                        "suffix": ""
                    },
                    {
                        "first": "Jason",
                        "middle": [],
                        "last": "Eisner",
                        "suffix": ""
                    },
                    {
                        "first": "Corby",
                        "middle": [],
                        "last": "Rosset",
                        "suffix": ""
                    },
                    {
                        "first": "Benjamin",
                        "middle": [],
                        "last": "Van Durme",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Kedzie",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL)",
                "volume": "",
                "issue": "",
                "pages": "13806--13834",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Helia Hashemi, Jason Eisner, Corby Rosset, Ben- jamin Van Durme, and Chris Kedzie. 2024. LLM- Rubric: A multidimensional, calibrated approach to automated evaluation of natural language texts. In Proceedings of the 62nd Annual Meeting of the Asso- ciation for Computational Linguistics (ACL), pages 13806-13834.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "b17",
                "title": "Deberta: Decoding-enhanced bert with disentangled attention",
                "authors": [
                    {
                        "first": "Pengcheng",
                        "middle": [],
                        "last": "He",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaodong",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Jianfeng",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Weizhu",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "International Conference on Learning Representations",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. 2021. Deberta: Decoding-enhanced bert with disentangled attention. In International Conference on Learning Representations.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "b18",
                "title": "How can we know when language models know? On the calibration of language models for question answering",
                "authors": [
                    {
                        "first": "Zhengbao",
                        "middle": [],
                        "last": "Jiang",
                        "suffix": ""
                    },
                    {
                        "first": "Jun",
                        "middle": [],
                        "last": "Araki",
                        "suffix": ""
                    },
                    {
                        "first": "Haibo",
                        "middle": [],
                        "last": "Ding",
                        "suffix": ""
                    },
                    {
                        "first": "Graham",
                        "middle": [],
                        "last": "Neubig",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "Transactions of the Association for Computational Linguistics",
                "volume": "9",
                "issue": "",
                "pages": "962--977",
                "other_ids": {
                    "DOI": [
                        "10.1162/tacl_a_00407"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Zhengbao Jiang, Jun Araki, Haibo Ding, and Graham Neubig. 2021. How can we know when language models know? On the calibration of language models for question answering. Transactions of the Associa- tion for Computational Linguistics, 9:962-977.",
                "links": null
            },
            "BIBREF19": {
                "ref_id": "b19",
                "title": "Language models(mostly) know what they know",
                "authors": [
                    {
                        "first": "Saurav",
                        "middle": [],
                        "last": "Kadavath",
                        "suffix": ""
                    },
                    {
                        "first": "Tom",
                        "middle": [],
                        "last": "Conerly",
                        "suffix": ""
                    },
                    {
                        "first": "Amanda",
                        "middle": [],
                        "last": "Askell",
                        "suffix": ""
                    },
                    {
                        "first": "Tom",
                        "middle": [],
                        "last": "Henighan",
                        "suffix": ""
                    },
                    {
                        "first": "Dawn",
                        "middle": [],
                        "last": "Drain",
                        "suffix": ""
                    },
                    {
                        "first": "Ethan",
                        "middle": [],
                        "last": "Perez",
                        "suffix": ""
                    },
                    {
                        "first": "Nicholas",
                        "middle": [],
                        "last": "Schiefer",
                        "suffix": ""
                    },
                    {
                        "first": "Zac",
                        "middle": [],
                        "last": "Hatfield-Dodds",
                        "suffix": ""
                    },
                    {
                        "first": "Nova",
                        "middle": [],
                        "last": "Dassarma",
                        "suffix": ""
                    },
                    {
                        "first": "Eli",
                        "middle": [],
                        "last": "Tran-Johnson",
                        "suffix": ""
                    },
                    {
                        "first": "Scott",
                        "middle": [],
                        "last": "Johnston",
                        "suffix": ""
                    },
                    {
                        "first": "Sheer",
                        "middle": [],
                        "last": "El-Showk",
                        "suffix": ""
                    },
                    {
                        "first": "Andy",
                        "middle": [],
                        "last": "Jones",
                        "suffix": ""
                    },
                    {
                        "first": "Nelson",
                        "middle": [],
                        "last": "Elhage",
                        "suffix": ""
                    },
                    {
                        "first": "Tristan",
                        "middle": [],
                        "last": "Hume",
                        "suffix": ""
                    },
                    {
                        "first": "Anna",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Yuntao",
                        "middle": [],
                        "last": "Bai",
                        "suffix": ""
                    },
                    {
                        "first": "Sam",
                        "middle": [],
                        "last": "Bowman",
                        "suffix": ""
                    },
                    {
                        "first": "Stanislav",
                        "middle": [],
                        "last": "Fort",
                        "suffix": ""
                    },
                    {
                        "first": "Deep",
                        "middle": [],
                        "last": "Ganguli",
                        "suffix": ""
                    },
                    {
                        "first": "Danny",
                        "middle": [],
                        "last": "Hernandez",
                        "suffix": ""
                    },
                    {
                        "first": "Josh",
                        "middle": [],
                        "last": "Jacobson",
                        "suffix": ""
                    },
                    {
                        "first": "Jackson",
                        "middle": [],
                        "last": "Kernion",
                        "suffix": ""
                    },
                    {
                        "first": "Shauna",
                        "middle": [],
                        "last": "Kravec",
                        "suffix": ""
                    },
                    {
                        "first": "Liane",
                        "middle": [],
                        "last": "Lovitt",
                        "suffix": ""
                    },
                    {
                        "first": "Kamal",
                        "middle": [],
                        "last": "Ndousse",
                        "suffix": ""
                    },
                    {
                        "first": "Catherine",
                        "middle": [],
                        "last": "Olsson",
                        "suffix": ""
                    },
                    {
                        "first": "Sam",
                        "middle": [],
                        "last": "Ringer",
                        "suffix": ""
                    },
                    {
                        "first": "Dario",
                        "middle": [],
                        "last": "Amodei",
                        "suffix": ""
                    },
                    {
                        "first": "Tom",
                        "middle": [],
                        "last": "Brown",
                        "suffix": ""
                    },
                    {
                        "first": "Jack",
                        "middle": [],
                        "last": "Clark",
                        "suffix": ""
                    },
                    {
                        "first": "Nicholas",
                        "middle": [],
                        "last": "Joseph",
                        "suffix": ""
                    },
                    {
                        "first": "Ben",
                        "middle": [],
                        "last": "Mann",
                        "suffix": ""
                    },
                    {
                        "first": "Sam",
                        "middle": [],
                        "last": "Mccandlish",
                        "suffix": ""
                    },
                    {
                        "first": "Chris",
                        "middle": [],
                        "last": "Olah",
                        "suffix": ""
                    },
                    {
                        "first": "Jared",
                        "middle": [],
                        "last": "Kaplan",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "DOI": [
                        "10.48550/arXiv.2207.05221"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, Scott Johnston, Sheer El-Showk, Andy Jones, Nelson Elhage, Tristan Hume, Anna Chen, Yuntao Bai, Sam Bowman, Stanislav Fort, Deep Ganguli, Danny Hernandez, Josh Jacobson, Jackson Kernion, Shauna Kravec, Liane Lovitt, Ka- mal Ndousse, Catherine Olsson, Sam Ringer, Dario Amodei, Tom Brown, Jack Clark, Nicholas Joseph, Ben Mann, Sam McCandlish, Chris Olah, and Jared Kaplan. 2022. Language models(mostly) know what they know. arXiv preprint. ArXiv:2207.05221 [cs].",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "b20",
                "title": "Calibration of encoder decoder models for neural machine translation",
                "authors": [
                    {
                        "first": "Aviral",
                        "middle": [],
                        "last": "Kumar",
                        "suffix": ""
                    },
                    {
                        "first": "Sunita",
                        "middle": [],
                        "last": "Sarawagi",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Aviral Kumar and Sunita Sarawagi. 2019. Calibration of encoder decoder models for neural machine trans- lation. ArXiv, abs/1903.00802.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "b21",
                "title": "Inferencetime intervention: Eliciting truthful answers from a language model",
                "authors": [
                    {
                        "first": "Kenneth",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Oam",
                        "middle": [],
                        "last": "Patel",
                        "suffix": ""
                    },
                    {
                        "first": "Fernanda",
                        "middle": [],
                        "last": "Vi\u00e9gas",
                        "suffix": ""
                    },
                    {
                        "first": "Hanspeter",
                        "middle": [],
                        "last": "Pfister",
                        "suffix": ""
                    },
                    {
                        "first": "Martin",
                        "middle": [],
                        "last": "Wattenberg",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "Advances in Neural Information Processing Systems",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Kenneth Li, Oam Patel, Fernanda Vi\u00e9gas, Hanspeter Pfister, and Martin Wattenberg. 2024. Inference- time intervention: Eliciting truthful answers from a language model. Advances in Neural Information Processing Systems, 36.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "b22",
                "title": "A statistical theory of target detection by pulsed radar",
                "authors": [
                    {
                        "first": "J",
                        "middle": [
                            "I"
                        ],
                        "last": "Marcum",
                        "suffix": ""
                    }
                ],
                "year": 1960,
                "venue": "IRE Transactions on Information Theory",
                "volume": "6",
                "issue": "2",
                "pages": "59--267",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "J.I. Marcum. 1960. A statistical theory of target detec- tion by pulsed radar. IRE Transactions on Informa- tion Theory, 6(2):59-267.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "b23",
                "title": "Language models implement simple Word2Vec-style vector arithmetic",
                "authors": [
                    {
                        "first": "Jack",
                        "middle": [],
                        "last": "Merullo",
                        "suffix": ""
                    },
                    {
                        "first": "Carsten",
                        "middle": [],
                        "last": "Eickhoff",
                        "suffix": ""
                    },
                    {
                        "first": "Ellie",
                        "middle": [],
                        "last": "Pavlick",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "volume": "1",
                "issue": "",
                "pages": "5030--5047",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2024.naacl-long.281"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Jack Merullo, Carsten Eickhoff, and Ellie Pavlick. 2024. Language models implement simple Word2Vec-style vector arithmetic. In Proceedings of the 2024 Con- ference of the North American Chapter of the Asso- ciation for Computational Linguistics: Human Lan- guage Technologies (Volume 1: Long Papers), pages 5030-5047, Mexico City, Mexico. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "b24",
                "title": "Reducing conversational agents' overconfidence through linguistic calibration",
                "authors": [
                    {
                        "first": "Sabrina",
                        "middle": [
                            "J"
                        ],
                        "last": "Mielke",
                        "suffix": ""
                    },
                    {
                        "first": "Arthur",
                        "middle": [],
                        "last": "Szlam",
                        "suffix": ""
                    },
                    {
                        "first": "Emily",
                        "middle": [],
                        "last": "Dinan",
                        "suffix": ""
                    },
                    {
                        "first": "Y-Lan",
                        "middle": [],
                        "last": "Boureau",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "",
                "volume": "10",
                "issue": "",
                "pages": "857--872",
                "other_ids": {
                    "DOI": [
                        "10.1162/tacl_a_00494"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Sabrina J. Mielke, Arthur Szlam, Emily Dinan, and Y- Lan Boureau. 2022. Reducing conversational agents' overconfidence through linguistic calibration. Trans- actions of the Association for Computational Linguis- tics, 10:857-872.",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "b25",
                "title": "On estimating regression",
                "authors": [
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Elizbar",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Nadaraya",
                        "suffix": ""
                    }
                ],
                "year": 1964,
                "venue": "Theory of Probability & Its Applications",
                "volume": "9",
                "issue": "1",
                "pages": "141--142",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Elizbar A Nadaraya. 1964. On estimating regression. Theory of Probability & Its Applications, 9(1):141- 142.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "b26",
                "title": "Binary classifier calibration: Nonparametric approach",
                "authors": [
                    {
                        "first": "Gregory",
                        "middle": [
                            "F"
                        ],
                        "last": "Mahdi Pakdaman Naeini",
                        "suffix": ""
                    },
                    {
                        "first": "Milos",
                        "middle": [],
                        "last": "Cooper",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Hauskrecht",
                        "suffix": ""
                    }
                ],
                "year": 2014,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mahdi Pakdaman Naeini, Gregory F. Cooper, and Milos Hauskrecht. 2014. Binary classifier calibration: Non- parametric approach. ArXiv, abs/1401.3390.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "b27",
                "title": "Obtaining well calibrated probabilities using bayesian binning",
                "authors": [
                    {
                        "first": "Gregory",
                        "middle": [
                            "F"
                        ],
                        "last": "Mahdi Pakdaman Naeini",
                        "suffix": ""
                    },
                    {
                        "first": "Milos",
                        "middle": [],
                        "last": "Cooper",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Hauskrecht",
                        "suffix": ""
                    }
                ],
                "year": 2015,
                "venue": "Proceedings of the ... AAAI Conference on Artificial Intelligence. AAAI Conference on Artificial Intelligence",
                "volume": "",
                "issue": "",
                "pages": "2901--2907",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Mahdi Pakdaman Naeini, Gregory F. Cooper, and Milos Hauskrecht. 2015. Obtaining well calibrated proba- bilities using bayesian binning. Proceedings of the ... AAAI Conference on Artificial Intelligence. AAAI Conference on Artificial Intelligence, 2015:2901- 2907.",
                "links": null
            },
            "BIBREF28": {
                "ref_id": "b28",
                "title": "Predicting good probabilities with supervised learning",
                "authors": [
                    {
                        "first": "Alexandru",
                        "middle": [],
                        "last": "Niculescu",
                        "suffix": ""
                    },
                    {
                        "first": "-Mizil",
                        "middle": [],
                        "last": "",
                        "suffix": ""
                    },
                    {
                        "first": "Rich",
                        "middle": [],
                        "last": "Caruana",
                        "suffix": ""
                    }
                ],
                "year": 2005,
                "venue": "Proceedings of the 22nd International Conference on Machine Learning (ICML)",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Alexandru Niculescu-Mizil and Rich Caruana. 2005. Predicting good probabilities with supervised learn- ing. In Proceedings of the 22nd International Con- ference on Machine Learning (ICML).",
                "links": null
            },
            "BIBREF29": {
                "ref_id": "b29",
                "title": "Histogram regression estimation using data-dependent partitions",
                "authors": [
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Nobel",
                        "suffix": ""
                    }
                ],
                "year": 1996,
                "venue": "The Annals of Statistics",
                "volume": "24",
                "issue": "3",
                "pages": "1084--1105",
                "other_ids": {
                    "DOI": [
                        "10.1214/aos/1032526958"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Andrew Nobel. 1996. Histogram regression estima- tion using data-dependent partitions. The Annals of Statistics, 24(3):1084 -1105.",
                "links": null
            },
            "BIBREF30": {
                "ref_id": "b30",
                "title": "Interpreting GPT: The logit lens",
                "authors": [],
                "year": 2020,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "nostalgebraist. 2020. Interpreting GPT: The logit lens. Blogpost.",
                "links": null
            },
            "BIBREF31": {
                "ref_id": "b31",
                "title": "Scikit-learn: Machine learning in Python",
                "authors": [
                    {
                        "first": "F",
                        "middle": [],
                        "last": "Pedregosa",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Varoquaux",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Gramfort",
                        "suffix": ""
                    },
                    {
                        "first": "V",
                        "middle": [],
                        "last": "Michel",
                        "suffix": ""
                    },
                    {
                        "first": "B",
                        "middle": [],
                        "last": "Thirion",
                        "suffix": ""
                    },
                    {
                        "first": "O",
                        "middle": [],
                        "last": "Grisel",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Blondel",
                        "suffix": ""
                    },
                    {
                        "first": "P",
                        "middle": [],
                        "last": "Prettenhofer",
                        "suffix": ""
                    },
                    {
                        "first": "R",
                        "middle": [],
                        "last": "Weiss",
                        "suffix": ""
                    },
                    {
                        "first": "V",
                        "middle": [],
                        "last": "Dubourg",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Vanderplas",
                        "suffix": ""
                    },
                    {
                        "first": "A",
                        "middle": [],
                        "last": "Passos",
                        "suffix": ""
                    },
                    {
                        "first": "D",
                        "middle": [],
                        "last": "Cournapeau",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Brucher",
                        "suffix": ""
                    },
                    {
                        "first": "M",
                        "middle": [],
                        "last": "Perrot",
                        "suffix": ""
                    },
                    {
                        "first": "E",
                        "middle": [],
                        "last": "Duchesnay",
                        "suffix": ""
                    }
                ],
                "year": 2011,
                "venue": "Journal of Machine Learning Research",
                "volume": "12",
                "issue": "",
                "pages": "2825--2830",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duch- esnay. 2011. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825-2830.",
                "links": null
            },
            "BIBREF32": {
                "ref_id": "b32",
                "title": "Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods",
                "authors": [
                    {
                        "first": "John",
                        "middle": [
                            "C"
                        ],
                        "last": "Platt",
                        "suffix": ""
                    }
                ],
                "year": 1999,
                "venue": "Advances in Large Margin Classifiers",
                "volume": "",
                "issue": "",
                "pages": "61--74",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "John C. Platt. 1999. Probabilistic outputs for support vector machines and comparisons to regularized like- lihood methods. In Advances in Large Margin Clas- sifiers, pages 61-74. MIT Press.",
                "links": null
            },
            "BIBREF33": {
                "ref_id": "b33",
                "title": "Sentence-BERT: Sentence embeddings using Siamese BERTnetworks",
                "authors": [
                    {
                        "first": "Nils",
                        "middle": [],
                        "last": "Reimers",
                        "suffix": ""
                    },
                    {
                        "first": "Iryna",
                        "middle": [],
                        "last": "Gurevych",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "volume": "",
                "issue": "",
                "pages": "3982--3992",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/D19-1410"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Nils Reimers and Iryna Gurevych. 2019. Sentence- BERT: Sentence embeddings using Siamese BERT- networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natu- ral Language Processing (EMNLP-IJCNLP), pages 3982-3992, Hong Kong, China. Association for Com- putational Linguistics.",
                "links": null
            },
            "BIBREF34": {
                "ref_id": "b34",
                "title": "BenchCLAMP: A benchmark for evaluating language models on syntactic and mantic parsing",
                "authors": [
                    {
                        "first": "Subhro",
                        "middle": [],
                        "last": "Roy",
                        "suffix": ""
                    },
                    {
                        "first": "Sam",
                        "middle": [],
                        "last": "Thomson",
                        "suffix": ""
                    },
                    {
                        "first": "Tongfei",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Richard",
                        "middle": [],
                        "last": "Shin",
                        "suffix": ""
                    },
                    {
                        "first": "Adam",
                        "middle": [],
                        "last": "Pauls",
                        "suffix": ""
                    },
                    {
                        "first": "Jason",
                        "middle": [],
                        "last": "Eisner",
                        "suffix": ""
                    },
                    {
                        "first": "Benjamin",
                        "middle": [],
                        "last": "Van Durme",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "Proceedings of the 37th International Conference on Neural Information Processing Systems, NIPS '23",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Subhro Roy, Sam Thomson, Tongfei Chen, Richard Shin, Adam Pauls, Jason Eisner, and Benjamin Van Durme. 2024. BenchCLAMP: A benchmark for evaluating language models on syntactic and mantic parsing. In Proceedings of the 37th Interna- tional Conference on Neural Information Processing Systems, NIPS '23, Red Hook, NY, USA. Curran Associates Inc.",
                "links": null
            },
            "BIBREF35": {
                "ref_id": "b35",
                "title": "Toolformer: Language models can teach themselves to use tools",
                "authors": [
                    {
                        "first": "Timo",
                        "middle": [],
                        "last": "Schick",
                        "suffix": ""
                    },
                    {
                        "first": "Jane",
                        "middle": [],
                        "last": "Dwivedi-Yu",
                        "suffix": ""
                    },
                    {
                        "first": "Roberto",
                        "middle": [],
                        "last": "Dess\u00ec",
                        "suffix": ""
                    },
                    {
                        "first": "Roberta",
                        "middle": [],
                        "last": "Raileanu",
                        "suffix": ""
                    },
                    {
                        "first": "Maria",
                        "middle": [],
                        "last": "Lomeli",
                        "suffix": ""
                    },
                    {
                        "first": "Eric",
                        "middle": [],
                        "last": "Hambro",
                        "suffix": ""
                    },
                    {
                        "first": "Luke",
                        "middle": [],
                        "last": "Zettlemoyer",
                        "suffix": ""
                    },
                    {
                        "first": "Nicola",
                        "middle": [],
                        "last": "Cancedda",
                        "suffix": ""
                    },
                    {
                        "first": "Thomas",
                        "middle": [],
                        "last": "Scialom",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "Advances in Neural Information Processing Systems",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Timo Schick, Jane Dwivedi-Yu, Roberto Dess\u00ec, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettle- moyer, Nicola Cancedda, and Thomas Scialom. 2024. Toolformer: Language models can teach themselves to use tools. Advances in Neural Information Pro- cessing Systems, 36.",
                "links": null
            },
            "BIBREF36": {
                "ref_id": "b36",
                "title": "Confident adaptive language modeling. Advances in Neural Information Processing Systems",
                "authors": [
                    {
                        "first": "Tal",
                        "middle": [],
                        "last": "Schuster",
                        "suffix": ""
                    },
                    {
                        "first": "Adam",
                        "middle": [],
                        "last": "Fisch",
                        "suffix": ""
                    },
                    {
                        "first": "Jai",
                        "middle": [],
                        "last": "Gupta",
                        "suffix": ""
                    },
                    {
                        "first": "Mostafa",
                        "middle": [],
                        "last": "Dehghani",
                        "suffix": ""
                    },
                    {
                        "first": "Dara",
                        "middle": [],
                        "last": "Bahri",
                        "suffix": ""
                    },
                    {
                        "first": "Vinh",
                        "middle": [],
                        "last": "Tran",
                        "suffix": ""
                    },
                    {
                        "first": "Yi",
                        "middle": [],
                        "last": "Tay",
                        "suffix": ""
                    },
                    {
                        "first": "Donald",
                        "middle": [],
                        "last": "Metzler",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "",
                "volume": "35",
                "issue": "",
                "pages": "17456--17472",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tal Schuster, Adam Fisch, Jai Gupta, Mostafa Dehghani, Dara Bahri, Vinh Tran, Yi Tay, and Donald Metzler. 2022. Confident adaptive language modeling. Ad- vances in Neural Information Processing Systems, 35:17456-17472.",
                "links": null
            },
            "BIBREF37": {
                "ref_id": "b37",
                "title": "LACIE: Listener-aware finetuning for confidence calibration in large language models",
                "authors": [
                    {
                        "first": "Elias",
                        "middle": [],
                        "last": "Stengel-Eskin",
                        "suffix": ""
                    },
                    {
                        "first": "Peter",
                        "middle": [],
                        "last": "Hase",
                        "suffix": ""
                    },
                    {
                        "first": "Mohit",
                        "middle": [],
                        "last": "Bansal",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2405.21028"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Elias Stengel-Eskin, Peter Hase, and Mohit Bansal. 2024. LACIE: Listener-aware finetuning for confi- dence calibration in large language models. Preprint, arXiv:2405.21028.",
                "links": null
            },
            "BIBREF38": {
                "ref_id": "b38",
                "title": "Calibrated interpretation: Confidence estimation in semantic parsing",
                "authors": [
                    {
                        "first": "Elias",
                        "middle": [],
                        "last": "Stengel-Eskin",
                        "suffix": ""
                    },
                    {
                        "first": "Benjamin",
                        "middle": [],
                        "last": "Van Durme",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "Transactions of the Association for Computational Linguistics",
                "volume": "11",
                "issue": "",
                "pages": "1213--1231",
                "other_ids": {
                    "DOI": [
                        "10.1162/tacl_a_00598"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Elias Stengel-Eskin and Benjamin Van Durme. 2023a. Calibrated interpretation: Confidence estimation in semantic parsing. Transactions of the Association for Computational Linguistics, 11:1213-1231.",
                "links": null
            },
            "BIBREF39": {
                "ref_id": "b39",
                "title": "Confidence-based trade-offs in semantic parsing",
                "authors": [
                    {
                        "first": "Elias",
                        "middle": [],
                        "last": "Stengel-Eskin",
                        "suffix": ""
                    },
                    {
                        "first": "Benjamin",
                        "middle": [],
                        "last": "Van Durme",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "2621--2629",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2023.emnlp-main.159"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Elias Stengel-Eskin and Benjamin Van Durme. 2023b. Did you mean . . . ? Confidence-based trade-offs in semantic parsing. In Proceedings of the 2023 Con- ference on Empirical Methods in Natural Language Processing, pages 2621-2629, Singapore.",
                "links": null
            },
            "BIBREF40": {
                "ref_id": "b40",
                "title": "Can unconditional language models recover arbitrary sentences?",
                "authors": [
                    {
                        "first": "Nishant",
                        "middle": [],
                        "last": "Subramani",
                        "suffix": ""
                    },
                    {
                        "first": "Samuel",
                        "middle": [],
                        "last": "Bowman",
                        "suffix": ""
                    },
                    {
                        "first": "Kyunghyun",
                        "middle": [],
                        "last": "Cho",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Advances in Neural Information Processing Systems",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Nishant Subramani, Samuel Bowman, and Kyunghyun Cho. 2019. Can unconditional language models re- cover arbitrary sentences? Advances in Neural Infor- mation Processing Systems, 32.",
                "links": null
            },
            "BIBREF41": {
                "ref_id": "b41",
                "title": "Discovering useful sentence representations from large pretrained language models",
                "authors": [
                    {
                        "first": "Nishant",
                        "middle": [],
                        "last": "Subramani",
                        "suffix": ""
                    },
                    {
                        "first": "Nivedita",
                        "middle": [],
                        "last": "Suresh",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2008.09049"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Nishant Subramani and Nivedita Suresh. 2020. Dis- covering useful sentence representations from large pretrained language models. arXiv preprint arXiv:2008.09049.",
                "links": null
            },
            "BIBREF42": {
                "ref_id": "b42",
                "title": "Extracting latent steering vectors from pretrained language models",
                "authors": [
                    {
                        "first": "Nishant",
                        "middle": [],
                        "last": "Subramani",
                        "suffix": ""
                    },
                    {
                        "first": "Nivedita",
                        "middle": [],
                        "last": "Suresh",
                        "suffix": ""
                    },
                    {
                        "first": "Matthew",
                        "middle": [],
                        "last": "Peters",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "Findings of the Association for Computational Linguistics: ACL 2022",
                "volume": "",
                "issue": "",
                "pages": "566--581",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2022.findings-acl.48"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Nishant Subramani, Nivedita Suresh, and Matthew Pe- ters. 2022. Extracting latent steering vectors from pretrained language models. In Findings of the Asso- ciation for Computational Linguistics: ACL 2022, pages 566-581, Dublin, Ireland. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF43": {
                "ref_id": "b43",
                "title": "BranchyNet: Fast inference via early exiting from deep neural networks",
                "authors": [
                    {
                        "first": "Bradley",
                        "middle": [],
                        "last": "Surat Teerapittayanon",
                        "suffix": ""
                    },
                    {
                        "first": "H",
                        "middle": [
                            "T"
                        ],
                        "last": "Mcdanel",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Kung",
                        "suffix": ""
                    }
                ],
                "year": 2017,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "DOI": [
                        "10.48550/arXiv.1709.01686"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Surat Teerapittayanon, Bradley McDanel, and H. T. Kung. 2017. BranchyNet: Fast inference via early exiting from deep neural networks. Preprint, arxiv:1709.01686 [cs]. Version: 1.",
                "links": null
            },
            "BIBREF44": {
                "ref_id": "b44",
                "title": "BERT rediscovers the classical NLP pipeline",
                "authors": [
                    {
                        "first": "Ian",
                        "middle": [],
                        "last": "Tenney",
                        "suffix": ""
                    },
                    {
                        "first": "Dipanjan",
                        "middle": [],
                        "last": "Das",
                        "suffix": ""
                    },
                    {
                        "first": "Ellie",
                        "middle": [],
                        "last": "Pavlick",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "4593--4601",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/P19-1452"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Ian Tenney, Dipanjan Das, and Ellie Pavlick. 2019. BERT rediscovers the classical NLP pipeline. In Proceedings of the 57th Annual Meeting of the Asso- ciation for Computational Linguistics, pages 4593- 4601, Florence, Italy. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF45": {
                "ref_id": "b45",
                "title": "Activation addition: Steering language models without optimization",
                "authors": [
                    {
                        "first": "Matt",
                        "middle": [],
                        "last": "Alexander",
                        "suffix": ""
                    },
                    {
                        "first": "Lisa",
                        "middle": [],
                        "last": "Turner",
                        "suffix": ""
                    },
                    {
                        "first": "Gavin",
                        "middle": [],
                        "last": "Thiergart",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [],
                        "last": "Leech",
                        "suffix": ""
                    },
                    {
                        "first": "Juan",
                        "middle": [
                            "J"
                        ],
                        "last": "Udell",
                        "suffix": ""
                    },
                    {
                        "first": "Ulisse",
                        "middle": [],
                        "last": "Vazquez",
                        "suffix": ""
                    },
                    {
                        "first": "Monte",
                        "middle": [],
                        "last": "Mini",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Macdiarmid",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2308.10248"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Alexander Matt Turner, Lisa Thiergart, Gavin Leech, David Udell, Juan J Vazquez, Ulisse Mini, and Monte MacDiarmid. 2023. Activation addition: Steer- ing language models without optimization. arXiv preprint arXiv:2308.10248.",
                "links": null
            },
            "BIBREF46": {
                "ref_id": "b46",
                "title": "LLMs in the imaginarium: Tool learning through simulated trial and error",
                "authors": [
                    {
                        "first": "Boshi",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Hao",
                        "middle": [],
                        "last": "Fang",
                        "suffix": ""
                    },
                    {
                        "first": "Jason",
                        "middle": [],
                        "last": "Eisner",
                        "suffix": ""
                    },
                    {
                        "first": "Benjamin",
                        "middle": [],
                        "last": "Van Durme",
                        "suffix": ""
                    },
                    {
                        "first": "Yu",
                        "middle": [],
                        "last": "Su",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "10583--10604",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2024.acl-long.570"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Boshi Wang, Hao Fang, Jason Eisner, Benjamin Van Durme, and Yu Su. 2024. LLMs in the imag- inarium: Tool learning through simulated trial and error. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Vol- ume 1: Long Papers), pages 10583-10604, Bangkok, Thailand. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF47": {
                "ref_id": "b47",
                "title": "Calibration in deep learning: A survey of the state-of-the-art",
                "authors": [
                    {
                        "first": "Cheng",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2308.01222"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Cheng Wang. 2024. Calibration in deep learn- ing: A survey of the state-of-the-art. Preprint, arXiv:2308.01222.",
                "links": null
            },
            "BIBREF48": {
                "ref_id": "b48",
                "title": "On the inference calibration of neural machine translation",
                "authors": [
                    {
                        "first": "Shuo",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Zhaopeng",
                        "middle": [],
                        "last": "Tu",
                        "suffix": ""
                    },
                    {
                        "first": "Shuming",
                        "middle": [],
                        "last": "Shi",
                        "suffix": ""
                    },
                    {
                        "first": "Yang",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "volume": "",
                "issue": "",
                "pages": "3070--3079",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2020.acl-main.278"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Shuo Wang, Zhaopeng Tu, Shuming Shi, and Yang Liu. 2020. On the inference calibration of neural machine translation. In Proceedings of the 58th Annual Meet- ing of the Association for Computational Linguistics, pages 3070-3079, Online. Association for Computa- tional Linguistics.",
                "links": null
            },
            "BIBREF49": {
                "ref_id": "b49",
                "title": "2021. seaborn: statistical data visualization",
                "authors": [
                    {
                        "first": "L",
                        "middle": [],
                        "last": "Michael",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Waskom",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "Journal of Open Source Software",
                "volume": "6",
                "issue": "60",
                "pages": "",
                "other_ids": {
                    "DOI": [
                        "10.21105/joss.03021"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Michael L. Waskom. 2021. seaborn: statistical data visualization. Journal of Open Source Software, 6(60):3021.",
                "links": null
            },
            "BIBREF50": {
                "ref_id": "b50",
                "title": "Smooth regression analysis",
                "authors": [
                    {
                        "first": "Geoffrey",
                        "middle": [
                            "S"
                        ],
                        "last": "Watson",
                        "suffix": ""
                    }
                ],
                "year": 1964,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "359--372",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Geoffrey S Watson. 1964. Smooth regression analysis. Sankhy\u0101: The Indian Journal of Statistics, Series A, pages 359-372.",
                "links": null
            },
            "BIBREF51": {
                "ref_id": "b51",
                "title": "Berkeley function calling leaderboard",
                "authors": [
                    {
                        "first": "Fanjia",
                        "middle": [],
                        "last": "Yan",
                        "suffix": ""
                    },
                    {
                        "first": "Huanzhi",
                        "middle": [],
                        "last": "Mao",
                        "suffix": ""
                    },
                    {
                        "first": "Charlie",
                        "middle": [],
                        "last": "Cheng-Jie",
                        "suffix": ""
                    },
                    {
                        "first": "Tianjun",
                        "middle": [],
                        "last": "Ji",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "G",
                        "middle": [],
                        "last": "Shishir",
                        "suffix": ""
                    },
                    {
                        "first": "Ion",
                        "middle": [],
                        "last": "Patil",
                        "suffix": ""
                    },
                    {
                        "first": "Joseph",
                        "middle": [
                            "E"
                        ],
                        "last": "Stoica",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Gonzalez",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Fanjia Yan, Huanzhi Mao, Charlie Cheng- Jie Ji, Tianjun Zhang, Shishir G. Patil, Ion Stoica, and Joseph E. Gonzalez. 2024. Berkeley function calling leaderboard. https://gorilla.cs.berkeley.edu/blogs/8_ berkeley_function_calling_leaderboard.html.",
                "links": null
            },
            "BIBREF52": {
                "ref_id": "b52",
                "title": "Xipeng Qiu, and Xuanjing Huang. 2023. Do large language models know what they don't know?",
                "authors": [
                    {
                        "first": "Zhangyue",
                        "middle": [],
                        "last": "Yin",
                        "suffix": ""
                    },
                    {
                        "first": "Qiushi",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    },
                    {
                        "first": "Qipeng",
                        "middle": [],
                        "last": "Guo",
                        "suffix": ""
                    },
                    {
                        "first": "Jiawen",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    }
                ],
                "year": null,
                "venue": "Findings of the Association for Computational Linguistics: ACL 2023",
                "volume": "",
                "issue": "",
                "pages": "8653--8665",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2023.findings-acl.551"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Zhangyue Yin, Qiushi Sun, Qipeng Guo, Jiawen Wu, Xipeng Qiu, and Xuanjing Huang. 2023. Do large language models know what they don't know? In Findings of the Association for Computational Lin- guistics: ACL 2023, pages 8653-8665, Toronto, Canada. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF53": {
                "ref_id": "b53",
                "title": "Jump to conclusions: Shortcutting transformers with linear transformations",
                "authors": [
                    {
                        "first": "Alexander",
                        "middle": [],
                        "last": "Yom Din",
                        "suffix": ""
                    },
                    {
                        "first": "Taelin",
                        "middle": [],
                        "last": "Karidi",
                        "suffix": ""
                    },
                    {
                        "first": "Leshem",
                        "middle": [],
                        "last": "Choshen",
                        "suffix": ""
                    },
                    {
                        "first": "Mor",
                        "middle": [],
                        "last": "Geva",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
                "volume": "",
                "issue": "",
                "pages": "9615--9625",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Alexander Yom Din, Taelin Karidi, Leshem Choshen, and Mor Geva. 2024. Jump to conclusions: Short- cutting transformers with linear transformations. In Proceedings of the 2024 Joint International Con- ference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 9615-9625, Torino, Italia. ELRA and ICCL.",
                "links": null
            },
            "BIBREF54": {
                "ref_id": "b54",
                "title": "BERTScore: Evaluating text generation with BERT",
                "authors": [
                    {
                        "first": "Tianyi",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Varsha",
                        "middle": [],
                        "last": "Kishore",
                        "suffix": ""
                    },
                    {
                        "first": "Felix",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Kilian",
                        "middle": [
                            "Q"
                        ],
                        "last": "Weinberger",
                        "suffix": ""
                    },
                    {
                        "first": "Yoav",
                        "middle": [],
                        "last": "Artzi",
                        "suffix": ""
                    }
                ],
                "year": 2020,
                "venue": "Proceedings of the International Conference on Learning Representations",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": null,
                "urls": [],
                "raw_text": "Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2020. BERTScore: Evaluating text generation with BERT. In Proceed- ings of the International Conference on Learning Representations.",
                "links": null
            },
            "BIBREF55": {
                "ref_id": "b55",
                "title": "Calibrate before use: Improving few-shot performance of language models",
                "authors": [
                    {
                        "first": "Tony",
                        "middle": [
                            "Z"
                        ],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Eric",
                        "middle": [],
                        "last": "Wallace",
                        "suffix": ""
                    },
                    {
                        "first": "Shi",
                        "middle": [],
                        "last": "Feng",
                        "suffix": ""
                    },
                    {
                        "first": "Dan",
                        "middle": [],
                        "last": "Klein",
                        "suffix": ""
                    },
                    {
                        "first": "Sameer",
                        "middle": [],
                        "last": "Singh",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "DOI": [
                        "10.48550/arXiv.2102.09690"
                    ],
                    "arXiv": [
                        "arXiv:2102.09690"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Tony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use: Improving few-shot performance of language mod- els. Technical Report arXiv:2102.09690, arXiv. ArXiv:2102.09690 [cs] type: article.",
                "links": null
            },
            "BIBREF56": {
                "ref_id": "b56",
                "title": "Non-programmers can programs indirectly via active examples: A case study with text-to-SQL",
                "authors": [
                    {
                        "first": "Ruiqi",
                        "middle": [],
                        "last": "Zhong",
                        "suffix": ""
                    },
                    {
                        "first": "Charlie",
                        "middle": [],
                        "last": "Snell",
                        "suffix": ""
                    },
                    {
                        "first": "Dan",
                        "middle": [],
                        "last": "Klein",
                        "suffix": ""
                    },
                    {
                        "first": "Jason",
                        "middle": [],
                        "last": "Eisner",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
                "volume": "",
                "issue": "",
                "pages": "5126--5152",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2023.emnlp-main.312"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Ruiqi Zhong, Charlie Snell, Dan Klein, and Jason Eis- ner. 2023. Non-programmers can programs indirectly via active examples: A case study with text-to-SQL. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Process- ing, pages 5126-5152, Singapore. Association for Computational Linguistics.",
                "links": null
            },
            "BIBREF57": {
                "ref_id": "b57",
                "title": "Online semantic parsing for latency reduction in task-oriented dialogue",
                "authors": [
                    {
                        "first": "Jiawei",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Jason",
                        "middle": [],
                        "last": "Eisner",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Newman",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics",
                "volume": "1",
                "issue": "",
                "pages": "1554--1576",
                "other_ids": {
                    "DOI": [
                        "10.18653/v1/2022.acl-long.110"
                    ]
                },
                "num": null,
                "urls": [],
                "raw_text": "Jiawei Zhou, Jason Eisner, Michael Newman, Em- manouil Antonios Platanios, and Sam Thomson. 2022. Online semantic parsing for latency reduc- tion in task-oriented dialogue. In Proceedings of the 60th Annual Meeting of the Association for Compu- tational Linguistics (Volume 1: Long Papers), pages 1554-1576, Dublin, Ireland. Association for Compu- tational Linguistics.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF0": {
                "num": null,
                "uris": null,
                "fig_num": "1",
                "text": "Figure 1: The MICE architecture.",
                "type_str": "figure"
            },
            "FIGREF1": {
                "num": null,
                "uris": null,
                "fig_num": "2",
                "text": "Figure 2: Example generations from the validation set across layers of the Llama3-8B-Instruct model. Generations from early layers (5, 15) are seemingly random, but later layers (25, 31) generate thematically relevant tokens. Layer 32 is the final layer.",
                "type_str": "figure"
            },
            "FIGREF2": {
                "num": null,
                "uris": null,
                "fig_num": "5",
                "text": "Figure 5: Feature importance for BERTScore features and confidence on the trained MICE RF model on the STE dataset for the Llama3 LLM.",
                "type_str": "figure"
            },
            "FIGREF3": {
                "num": null,
                "uris": null,
                "fig_num": "6",
                "text": "Figure 6: Coefficients for the trained MICE LR model on the STE dataset for the Llama3 LLM.",
                "type_str": "figure"
            },
            "FIGREF4": {
                "num": null,
                "uris": null,
                "fig_num": "7",
                "text": "Figure 7: Sample complexity: AUC of MICE models and HRE baselines as the size of the training set varies on the Llama3-8B-Instruct model. Error bars are one standard deviation.",
                "type_str": "figure"
            }
        }
    }
}